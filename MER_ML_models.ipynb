{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346da09f-aac1-4383-8dae-533bb1f0646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"hello world\")\n",
    "FEATURES_PATH = 'DEAM/features'\n",
    "VALENCE_FILE = 'DEAM/annotations/annotations averaged per song/song_level/static_annotations_averaged_songs_1_2000.csv'\n",
    "GENRE_FILE = 'DEAM/metadata/metadata_2013.csv'\n",
    "\n",
    "NUMBER_FILES = 2000\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5aad4258-75e8-49f1-86c2-bd79a9b11030",
   "metadata": {},
   "source": [
    "Extracción de la media de las caracterísitcas para cada canción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f778f3-72f7-4948-a211-445babf166e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFeaturesFromFile (file_name):\n",
    "    features_values = []\n",
    "    with open('DEAM/features/' + file_name, newline='') as csvfile:\n",
    "        data = list(csv.reader(csvfile, delimiter=';'))\n",
    "    for i in range (1, len(data[1])):\n",
    "        media = 0.0\n",
    "        suma = 0.0\n",
    "        #print(data[0][i], end=\"\" + \" = \")\n",
    "        for j in range (1, len(data)):\n",
    "            #print(str(float(data[j][i]))+ \", \", end=\"\")  \n",
    "            suma += float((data[j][i]))\n",
    "            #suma = suma + float((data[j][i]))\n",
    "            media = suma / (len(data) - 1)\n",
    "        #print(media)\n",
    "        #print(\"\")\n",
    "        features_values.append(media)\n",
    "    return features_values\n",
    "    #print(features_values)\n",
    "#loadFeaturesFromFile('2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49061e3-73ab-4967-915f-31d7889fc728",
   "metadata": {},
   "source": [
    "Extracción de nombre de las caracterísiticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6566cd4-c4cf-4851-b7d6-8f533e5aaac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeaturesNames():\n",
    "    with open('DEAM/features/2.csv', newline='') as csvfile:\n",
    "        data = list(csv.reader(csvfile, delimiter=';'))\n",
    "    features = data[0]\n",
    "    features = features[1:]\n",
    "    #print(len(features))\n",
    "    #print(features)\n",
    "    return features\n",
    "\n",
    "features = extractFeaturesNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201556b-eaf0-4f29-8c3b-2bfdc5da10fc",
   "metadata": {},
   "source": [
    "Crear tabla con las características por cancion y los datos de valencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f52fd7f-7727-493c-bce0-3ca2e5c39a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataFile(file_data, files_number):\n",
    "    \n",
    "    # create the header of the matrix (features and values of 2 file)\n",
    "    columns_name = ['file'] + features + ['valence'] + ['arousal']\n",
    "    df = pd.DataFrame([], columns=columns_name)\n",
    "    df.to_csv(file_data + \".csv\")\n",
    "    \n",
    "    # extract the name of the files\n",
    "    features_files = os.listdir(FEATURES_PATH)\n",
    "\n",
    "    #extract valence values from files\n",
    "    valence_matrix = pd.read_csv(VALENCE_FILE)\n",
    "    valences = valence_matrix[['song_id', ' valence_mean', ' arousal_mean']]\n",
    "    \n",
    "    \n",
    "    # fill the matrix with data\n",
    "    num = 1\n",
    "    song_id = 0\n",
    "    for file in features_files:\n",
    "        song_id = int(file[:-4])\n",
    "    \n",
    "        if song_id <= 1999:\n",
    "            valence_for_song = (valences[valences['song_id'] == song_id][' valence_mean']).iloc[0] \n",
    "            arousal_for_song = (valences[valences['song_id'] == song_id][' arousal_mean']).iloc[0] \n",
    "            feat = [num] + [file] + loadFeaturesFromFile(file) + [valence_for_song] + [arousal_for_song]\n",
    "            \n",
    "            with open(file_data + '.csv', mode='a', newline='') as file:  \n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(feat)\n",
    "            num = num + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "createDataFile('recap_data', NUMBER_FILES)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd279f3-912b-4514-ab10-3b955743d552",
   "metadata": {},
   "source": [
    "Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e841151-9f74-436c-bba1-2ae433b1c4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>F0final_sma_stddev</th>\n",
       "      <th>F0final_sma_amean</th>\n",
       "      <th>voicingFinalUnclipped_sma_stddev</th>\n",
       "      <th>voicingFinalUnclipped_sma_amean</th>\n",
       "      <th>jitterLocal_sma_stddev</th>\n",
       "      <th>jitterLocal_sma_amean</th>\n",
       "      <th>jitterDDP_sma_stddev</th>\n",
       "      <th>jitterDDP_sma_amean</th>\n",
       "      <th>...</th>\n",
       "      <th>pcm_fftMag_mfcc_sma_de[11]_stddev</th>\n",
       "      <th>pcm_fftMag_mfcc_sma_de[11]_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma_de[12]_stddev</th>\n",
       "      <th>pcm_fftMag_mfcc_sma_de[12]_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma_de[13]_stddev</th>\n",
       "      <th>pcm_fftMag_mfcc_sma_de[13]_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma_de[14]_stddev</th>\n",
       "      <th>pcm_fftMag_mfcc_sma_de[14]_amean</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122.csv</td>\n",
       "      <td>72.455493</td>\n",
       "      <td>121.999593</td>\n",
       "      <td>0.032615</td>\n",
       "      <td>0.743192</td>\n",
       "      <td>0.121745</td>\n",
       "      <td>0.078061</td>\n",
       "      <td>0.133986</td>\n",
       "      <td>0.088676</td>\n",
       "      <td>...</td>\n",
       "      <td>2.132022</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>1.971246</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1.848157</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.709386</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>736.csv</td>\n",
       "      <td>55.493567</td>\n",
       "      <td>174.128629</td>\n",
       "      <td>0.032542</td>\n",
       "      <td>0.785903</td>\n",
       "      <td>0.072172</td>\n",
       "      <td>0.051077</td>\n",
       "      <td>0.085079</td>\n",
       "      <td>0.053610</td>\n",
       "      <td>...</td>\n",
       "      <td>1.336499</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.217145</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>1.238022</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>1.116202</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1042.csv</td>\n",
       "      <td>39.409995</td>\n",
       "      <td>106.558921</td>\n",
       "      <td>0.037863</td>\n",
       "      <td>0.772938</td>\n",
       "      <td>0.127640</td>\n",
       "      <td>0.094258</td>\n",
       "      <td>0.143104</td>\n",
       "      <td>0.103178</td>\n",
       "      <td>...</td>\n",
       "      <td>2.221844</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>2.156892</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>2.053561</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>1.702499</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1275.csv</td>\n",
       "      <td>22.590408</td>\n",
       "      <td>82.188975</td>\n",
       "      <td>0.033827</td>\n",
       "      <td>0.763277</td>\n",
       "      <td>0.104742</td>\n",
       "      <td>0.072661</td>\n",
       "      <td>0.103858</td>\n",
       "      <td>0.071290</td>\n",
       "      <td>...</td>\n",
       "      <td>2.215059</td>\n",
       "      <td>-0.001149</td>\n",
       "      <td>1.937555</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>1.802331</td>\n",
       "      <td>-0.000547</td>\n",
       "      <td>1.680737</td>\n",
       "      <td>-0.001378</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1892.csv</td>\n",
       "      <td>65.854057</td>\n",
       "      <td>113.440481</td>\n",
       "      <td>0.029411</td>\n",
       "      <td>0.743594</td>\n",
       "      <td>0.107730</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>0.078096</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329009</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>2.004704</td>\n",
       "      <td>-0.001736</td>\n",
       "      <td>1.909060</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>1.753582</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>1739</td>\n",
       "      <td>357.csv</td>\n",
       "      <td>44.839563</td>\n",
       "      <td>111.343268</td>\n",
       "      <td>0.036957</td>\n",
       "      <td>0.768153</td>\n",
       "      <td>0.113309</td>\n",
       "      <td>0.070202</td>\n",
       "      <td>0.123682</td>\n",
       "      <td>0.076547</td>\n",
       "      <td>...</td>\n",
       "      <td>1.955979</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>1.812231</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>1.671897</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>1.513882</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1740</td>\n",
       "      <td>1648.csv</td>\n",
       "      <td>55.258397</td>\n",
       "      <td>141.024205</td>\n",
       "      <td>0.027661</td>\n",
       "      <td>0.798257</td>\n",
       "      <td>0.135815</td>\n",
       "      <td>0.084960</td>\n",
       "      <td>0.159669</td>\n",
       "      <td>0.101305</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945865</td>\n",
       "      <td>-0.002976</td>\n",
       "      <td>1.697553</td>\n",
       "      <td>-0.004987</td>\n",
       "      <td>1.501074</td>\n",
       "      <td>-0.002797</td>\n",
       "      <td>1.444453</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1741</td>\n",
       "      <td>1493.csv</td>\n",
       "      <td>157.875615</td>\n",
       "      <td>412.318588</td>\n",
       "      <td>0.084103</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.038528</td>\n",
       "      <td>0.023111</td>\n",
       "      <td>0.036928</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>...</td>\n",
       "      <td>4.364806</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>3.410945</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>2.564815</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>2.606689</td>\n",
       "      <td>-0.003860</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1742</td>\n",
       "      <td>1784.csv</td>\n",
       "      <td>64.431062</td>\n",
       "      <td>108.279179</td>\n",
       "      <td>0.070644</td>\n",
       "      <td>0.758823</td>\n",
       "      <td>0.124175</td>\n",
       "      <td>0.075927</td>\n",
       "      <td>0.142210</td>\n",
       "      <td>0.090704</td>\n",
       "      <td>...</td>\n",
       "      <td>2.248901</td>\n",
       "      <td>-0.004967</td>\n",
       "      <td>1.913097</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>2.023299</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>1.714624</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1743</td>\n",
       "      <td>1224.csv</td>\n",
       "      <td>27.091138</td>\n",
       "      <td>86.051487</td>\n",
       "      <td>0.039693</td>\n",
       "      <td>0.773344</td>\n",
       "      <td>0.084674</td>\n",
       "      <td>0.051586</td>\n",
       "      <td>0.084044</td>\n",
       "      <td>0.057365</td>\n",
       "      <td>...</td>\n",
       "      <td>2.175545</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>2.398786</td>\n",
       "      <td>-0.001349</td>\n",
       "      <td>1.759458</td>\n",
       "      <td>-0.003256</td>\n",
       "      <td>1.899548</td>\n",
       "      <td>-0.003618</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1743 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      file  F0final_sma_stddev  F0final_sma_amean  \\\n",
       "0              1   122.csv           72.455493         121.999593   \n",
       "1              2   736.csv           55.493567         174.128629   \n",
       "2              3  1042.csv           39.409995         106.558921   \n",
       "3              4  1275.csv           22.590408          82.188975   \n",
       "4              5  1892.csv           65.854057         113.440481   \n",
       "...          ...       ...                 ...                ...   \n",
       "1738        1739   357.csv           44.839563         111.343268   \n",
       "1739        1740  1648.csv           55.258397         141.024205   \n",
       "1740        1741  1493.csv          157.875615         412.318588   \n",
       "1741        1742  1784.csv           64.431062         108.279179   \n",
       "1742        1743  1224.csv           27.091138          86.051487   \n",
       "\n",
       "      voicingFinalUnclipped_sma_stddev  voicingFinalUnclipped_sma_amean  \\\n",
       "0                             0.032615                         0.743192   \n",
       "1                             0.032542                         0.785903   \n",
       "2                             0.037863                         0.772938   \n",
       "3                             0.033827                         0.763277   \n",
       "4                             0.029411                         0.743594   \n",
       "...                                ...                              ...   \n",
       "1738                          0.036957                         0.768153   \n",
       "1739                          0.027661                         0.798257   \n",
       "1740                          0.084103                         0.806587   \n",
       "1741                          0.070644                         0.758823   \n",
       "1742                          0.039693                         0.773344   \n",
       "\n",
       "      jitterLocal_sma_stddev  jitterLocal_sma_amean  jitterDDP_sma_stddev  \\\n",
       "0                   0.121745               0.078061              0.133986   \n",
       "1                   0.072172               0.051077              0.085079   \n",
       "2                   0.127640               0.094258              0.143104   \n",
       "3                   0.104742               0.072661              0.103858   \n",
       "4                   0.107730               0.075472              0.112885   \n",
       "...                      ...                    ...                   ...   \n",
       "1738                0.113309               0.070202              0.123682   \n",
       "1739                0.135815               0.084960              0.159669   \n",
       "1740                0.038528               0.023111              0.036928   \n",
       "1741                0.124175               0.075927              0.142210   \n",
       "1742                0.084674               0.051586              0.084044   \n",
       "\n",
       "      jitterDDP_sma_amean  ...  pcm_fftMag_mfcc_sma_de[11]_stddev  \\\n",
       "0                0.088676  ...                           2.132022   \n",
       "1                0.053610  ...                           1.336499   \n",
       "2                0.103178  ...                           2.221844   \n",
       "3                0.071290  ...                           2.215059   \n",
       "4                0.078096  ...                           2.329009   \n",
       "...                   ...  ...                                ...   \n",
       "1738             0.076547  ...                           1.955979   \n",
       "1739             0.101305  ...                           1.945865   \n",
       "1740             0.019565  ...                           4.364806   \n",
       "1741             0.090704  ...                           2.248901   \n",
       "1742             0.057365  ...                           2.175545   \n",
       "\n",
       "      pcm_fftMag_mfcc_sma_de[11]_amean  pcm_fftMag_mfcc_sma_de[12]_stddev  \\\n",
       "0                            -0.000408                           1.971246   \n",
       "1                             0.000298                           1.217145   \n",
       "2                            -0.003346                           2.156892   \n",
       "3                            -0.001149                           1.937555   \n",
       "4                            -0.000771                           2.004704   \n",
       "...                                ...                                ...   \n",
       "1738                          0.000230                           1.812231   \n",
       "1739                         -0.002976                           1.697553   \n",
       "1740                          0.000448                           3.410945   \n",
       "1741                         -0.004967                           1.913097   \n",
       "1742                         -0.005025                           2.398786   \n",
       "\n",
       "      pcm_fftMag_mfcc_sma_de[12]_amean  pcm_fftMag_mfcc_sma_de[13]_stddev  \\\n",
       "0                             0.000047                           1.848157   \n",
       "1                            -0.000021                           1.238022   \n",
       "2                            -0.000577                           2.053561   \n",
       "3                             0.003023                           1.802331   \n",
       "4                            -0.001736                           1.909060   \n",
       "...                                ...                                ...   \n",
       "1738                          0.000394                           1.671897   \n",
       "1739                         -0.004987                           1.501074   \n",
       "1740                          0.006046                           2.564815   \n",
       "1741                          0.001232                           2.023299   \n",
       "1742                         -0.001349                           1.759458   \n",
       "\n",
       "      pcm_fftMag_mfcc_sma_de[13]_amean  pcm_fftMag_mfcc_sma_de[14]_stddev  \\\n",
       "0                             0.000444                           1.709386   \n",
       "1                             0.000212                           1.116202   \n",
       "2                             0.001272                           1.702499   \n",
       "3                            -0.000547                           1.680737   \n",
       "4                             0.001739                           1.753582   \n",
       "...                                ...                                ...   \n",
       "1738                         -0.000347                           1.513882   \n",
       "1739                         -0.002797                           1.444453   \n",
       "1740                         -0.000453                           2.606689   \n",
       "1741                          0.002849                           1.714624   \n",
       "1742                         -0.003256                           1.899548   \n",
       "\n",
       "      pcm_fftMag_mfcc_sma_de[14]_amean  valence  arousal  \n",
       "0                             0.000424      5.5      4.6  \n",
       "1                             0.000100      2.7      3.7  \n",
       "2                             0.001127      5.0      4.3  \n",
       "3                            -0.001378      3.5      2.8  \n",
       "4                            -0.001443      5.1      6.1  \n",
       "...                                ...      ...      ...  \n",
       "1738                         -0.000573      4.8      6.5  \n",
       "1739                         -0.005020      3.9      2.5  \n",
       "1740                         -0.003860      4.0      6.1  \n",
       "1741                          0.000608      5.5      5.1  \n",
       "1742                         -0.003618      6.2      6.8  \n",
       "\n",
       "[1743 rows x 264 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = pd.read_csv('recap_data.csv')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20abccf-d6b4-4501-85e4-bce5ff2c93f4",
   "metadata": {},
   "source": [
    "Seleccionar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f7de3fa-f9ad-4107-bfb1-d33e22ae048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explicative = matrix.drop(columns=['valence', 'file', 'Unnamed: 0', 'arousal'])\n",
    "objective_valence = matrix.valence\n",
    "objective_arousal = matrix.arousal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae15e57-92b9-4d3f-a782-9d0caa7a2ace",
   "metadata": {},
   "source": [
    "## ------ VALENCIA ------ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284aec9d-cb37-4e95-bf5f-ad309f9ee7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- seleccion de variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(explicative, objective_valence, test_size=0.03, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e3287-994f-460c-97c0-7f02d600fc1a",
   "metadata": {},
   "source": [
    "# --- Árbol de decisión --- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdcd5b-0da9-4aa8-a5b6-4ab887d5fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "grid_hp_tree_reg = {\n",
    "    'criterion': ['squared_error', 'friedman_mse', 'absolute_error'],\n",
    "    'splitter': ['best', 'random'], \n",
    "    'max_depth': [0, 5, 10], \n",
    "    'min_samples_split': [2, 4], \n",
    "    'min_samples_leaf': [1, 3], \n",
    "    'max_features': [None, 'sqrt', 'log2'], \n",
    "    'random_state': [None, 3, 5],\n",
    "    'max_leaf_nodes': [None, 3]\n",
    "}\n",
    "\n",
    "tree_regr_model_valence = GridSearchCV(\n",
    "    estimator = DecisionTreeRegressor(), \n",
    "    param_grid = grid_hp_tree_reg, \n",
    "    cv = 2,\n",
    "    n_jobs = -1,\n",
    "    verbose = 10,\n",
    ")\n",
    "\n",
    "tree_regr_model_valence.fit(X_train_val, y_train_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374315ea-5e67-4801-9b96-a89082e265d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_regr_model_valence.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747ebe9-6ddf-4282-809d-b5d94a887af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_regr_model_valence.score(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c0487-4e19-4d21-a682-af016ed0e9e1",
   "metadata": {},
   "source": [
    "# ---- Random forest ---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf7b4c1-4755-4f9a-902d-9db7559d7169",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m      4\u001b[0m grid_hp_random_forest \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabsolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     16\u001b[0m random_forest_model_valence \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     17\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m RandomForestRegressor(), \n\u001b[1;32m     18\u001b[0m     param_grid \u001b[38;5;241m=\u001b[39m grid_hp_random_forest, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m random_forest_model_valence\u001b[38;5;241m.\u001b[39mfit(X_train_val, y_train_val)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_val' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "grid_hp_random_forest = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'criterion': ['squared_error', 'absolute_error'],\n",
    "    'max_depth': [None, 5, 10], \n",
    "    'min_samples_split': [2, 4], \n",
    "    'min_samples_leaf': [1, 3], \n",
    "    'max_features': [None, 'sqrt', 'log2'], \n",
    "    'random_state': [None, 3, 5],\n",
    "    'max_leaf_nodes': [None, 3],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_forest_model_valence = GridSearchCV(\n",
    "    estimator = RandomForestRegressor(), \n",
    "    param_grid = grid_hp_random_forest, \n",
    "    cv = 2,\n",
    "    n_jobs = -1,\n",
    "    verbose = 10,\n",
    ")\n",
    "\n",
    "random_forest_model_valence.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5bb45-efb5-47a3-bd57-737ef40232e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model_valence.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df05c02-90e3-4383-b85c-72da8a465606",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model_valence.score(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6458a4-d4bf-4435-97b9-5e027c9ab5c1",
   "metadata": {},
   "source": [
    "# ---- Linear regression ---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52babb0-4aa7-4ba6-977e-4ef5d5fd1b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=LinearRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;copy_X&#x27;: [True, False],\n",
       "                         &#x27;fit_intercept&#x27;: [True, False], &#x27;n_jobs&#x27;: [None, -1],\n",
       "                         &#x27;positive&#x27;: [True, False]},\n",
       "             verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=LinearRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;copy_X&#x27;: [True, False],\n",
       "                         &#x27;fit_intercept&#x27;: [True, False], &#x27;n_jobs&#x27;: [None, -1],\n",
       "                         &#x27;positive&#x27;: [True, False]},\n",
       "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=LinearRegression(), n_jobs=-1,\n",
       "             param_grid={'copy_X': [True, False],\n",
       "                         'fit_intercept': [True, False], 'n_jobs': [None, -1],\n",
       "                         'positive': [True, False]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "grid_hp_linear_reg = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'n_jobs': [None, -1],\n",
    "    'positive': [True, False]\n",
    "}\n",
    "\n",
    "linear_reg_model_valence = GridSearchCV(\n",
    "    estimator = LinearRegression(), \n",
    "    param_grid = grid_hp_linear_reg, \n",
    "    cv = 2,\n",
    "    n_jobs = -1,\n",
    "    verbose = 10,\n",
    ")\n",
    "\n",
    "linear_reg_model_valence.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de306041-4acb-4af8-8f44-935c7e2470c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_X': True, 'fit_intercept': False, 'n_jobs': None, 'positive': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 1/16] START copy_X=True, fit_intercept=True, n_jobs=None, positive=True\n",
      "[CV 2/2; 1/16] END copy_X=True, fit_intercept=True, n_jobs=None, positive=True;, score=0.480 total time=   0.1s\n",
      "[CV 2/2; 3/16] START copy_X=True, fit_intercept=True, n_jobs=-1, positive=True..\n",
      "[CV 2/2; 3/16] END copy_X=True, fit_intercept=True, n_jobs=-1, positive=True;, score=0.480 total time=   0.1s\n",
      "[CV 2/2; 4/16] START copy_X=True, fit_intercept=True, n_jobs=-1, positive=False.\n",
      "[CV 2/2; 4/16] END copy_X=True, fit_intercept=True, n_jobs=-1, positive=False;, score=0.194 total time=   0.1s\n",
      "[CV 2/2; 6/16] START copy_X=True, fit_intercept=False, n_jobs=None, positive=False\n",
      "[CV 2/2; 6/16] END copy_X=True, fit_intercept=False, n_jobs=None, positive=False;, score=0.167 total time=   0.0s\n",
      "[CV 2/2; 7/16] START copy_X=True, fit_intercept=False, n_jobs=-1, positive=True.\n",
      "[CV 2/2; 7/16] END copy_X=True, fit_intercept=False, n_jobs=-1, positive=True;, score=0.482 total time=   0.1s\n",
      "[CV 2/2; 10/16] START copy_X=False, fit_intercept=True, n_jobs=None, positive=False\n",
      "[CV 2/2; 10/16] END copy_X=False, fit_intercept=True, n_jobs=None, positive=False;, score=0.194 total time=   0.1s\n",
      "[CV 1/2; 12/16] START copy_X=False, fit_intercept=True, n_jobs=-1, positive=False\n",
      "[CV 1/2; 12/16] END copy_X=False, fit_intercept=True, n_jobs=-1, positive=False;, score=0.301 total time=   0.0s\n",
      "[CV 1/2; 13/16] START copy_X=False, fit_intercept=False, n_jobs=None, positive=True\n",
      "[CV 1/2; 13/16] END copy_X=False, fit_intercept=False, n_jobs=None, positive=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 16/16] START copy_X=False, fit_intercept=False, n_jobs=-1, positive=False\n",
      "[CV 2/2; 16/16] END copy_X=False, fit_intercept=False, n_jobs=-1, positive=False;, score=0.167 total time=   0.0s\n",
      "[CV 1/2; 2/16] START copy_X=True, fit_intercept=True, n_jobs=None, positive=False\n",
      "[CV 1/2; 2/16] END copy_X=True, fit_intercept=True, n_jobs=None, positive=False;, score=0.301 total time=   0.2s\n",
      "[CV 1/2; 6/16] START copy_X=True, fit_intercept=False, n_jobs=None, positive=False\n",
      "[CV 1/2; 6/16] END copy_X=True, fit_intercept=False, n_jobs=None, positive=False;, score=0.301 total time=   0.0s\n",
      "[CV 1/2; 7/16] START copy_X=True, fit_intercept=False, n_jobs=-1, positive=True.\n",
      "[CV 1/2; 7/16] END copy_X=True, fit_intercept=False, n_jobs=-1, positive=True;, score=0.474 total time=   0.2s\n",
      "[CV 1/2; 10/16] START copy_X=False, fit_intercept=True, n_jobs=None, positive=False\n",
      "[CV 1/2; 10/16] END copy_X=False, fit_intercept=True, n_jobs=None, positive=False;, score=0.301 total time=   0.1s\n",
      "[CV 2/2; 11/16] START copy_X=False, fit_intercept=True, n_jobs=-1, positive=True\n",
      "[CV 2/2; 11/16] END copy_X=False, fit_intercept=True, n_jobs=-1, positive=True;, score=0.480 total time=   0.1s\n",
      "[CV 1/2; 14/16] START copy_X=False, fit_intercept=False, n_jobs=None, positive=False\n",
      "[CV 1/2; 14/16] END copy_X=False, fit_intercept=False, n_jobs=None, positive=False;, score=0.301 total time=   0.1s\n",
      "[CV 1/2; 15/16] START copy_X=False, fit_intercept=False, n_jobs=-1, positive=True\n",
      "[CV 1/2; 15/16] END copy_X=False, fit_intercept=False, n_jobs=-1, positive=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 2/16] START copy_X=True, fit_intercept=True, n_jobs=None, positive=False\n",
      "[CV 2/2; 2/16] END copy_X=True, fit_intercept=True, n_jobs=None, positive=False;, score=0.194 total time=   0.1s\n",
      "[CV 1/2; 5/16] START copy_X=True, fit_intercept=False, n_jobs=None, positive=True\n",
      "[CV 1/2; 5/16] END copy_X=True, fit_intercept=False, n_jobs=None, positive=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 8/16] START copy_X=True, fit_intercept=False, n_jobs=-1, positive=False\n",
      "[CV 2/2; 8/16] END copy_X=True, fit_intercept=False, n_jobs=-1, positive=False;, score=0.167 total time=   0.1s\n",
      "[CV 2/2; 9/16] START copy_X=False, fit_intercept=True, n_jobs=None, positive=True\n",
      "[CV 2/2; 9/16] END copy_X=False, fit_intercept=True, n_jobs=None, positive=True;, score=0.480 total time=   0.1s\n",
      "[CV 1/2; 11/16] START copy_X=False, fit_intercept=True, n_jobs=-1, positive=True\n",
      "[CV 1/2; 11/16] END copy_X=False, fit_intercept=True, n_jobs=-1, positive=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 14/16] START copy_X=False, fit_intercept=False, n_jobs=None, positive=False\n",
      "[CV 2/2; 14/16] END copy_X=False, fit_intercept=False, n_jobs=None, positive=False;, score=0.167 total time=   0.0s\n",
      "[CV 2/2; 15/16] START copy_X=False, fit_intercept=False, n_jobs=-1, positive=True\n",
      "[CV 2/2; 15/16] END copy_X=False, fit_intercept=False, n_jobs=-1, positive=True;, score=0.482 total time=   0.1s\n",
      "[CV 1/2; 1/16] START copy_X=True, fit_intercept=True, n_jobs=None, positive=True\n",
      "[CV 1/2; 1/16] END copy_X=True, fit_intercept=True, n_jobs=None, positive=True;, score=0.474 total time=   0.1s\n",
      "[CV 1/2; 3/16] START copy_X=True, fit_intercept=True, n_jobs=-1, positive=True..\n",
      "[CV 1/2; 3/16] END copy_X=True, fit_intercept=True, n_jobs=-1, positive=True;, score=0.474 total time=   0.1s\n",
      "[CV 1/2; 4/16] START copy_X=True, fit_intercept=True, n_jobs=-1, positive=False.\n",
      "[CV 1/2; 4/16] END copy_X=True, fit_intercept=True, n_jobs=-1, positive=False;, score=0.301 total time=   0.1s\n",
      "[CV 2/2; 5/16] START copy_X=True, fit_intercept=False, n_jobs=None, positive=True\n",
      "[CV 2/2; 5/16] END copy_X=True, fit_intercept=False, n_jobs=None, positive=True;, score=0.482 total time=   0.1s\n",
      "[CV 1/2; 8/16] START copy_X=True, fit_intercept=False, n_jobs=-1, positive=False\n",
      "[CV 1/2; 8/16] END copy_X=True, fit_intercept=False, n_jobs=-1, positive=False;, score=0.301 total time=   0.0s\n",
      "[CV 1/2; 9/16] START copy_X=False, fit_intercept=True, n_jobs=None, positive=True\n",
      "[CV 1/2; 9/16] END copy_X=False, fit_intercept=True, n_jobs=None, positive=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 12/16] START copy_X=False, fit_intercept=True, n_jobs=-1, positive=False\n",
      "[CV 2/2; 12/16] END copy_X=False, fit_intercept=True, n_jobs=-1, positive=False;, score=0.194 total time=   0.0s\n",
      "[CV 2/2; 13/16] START copy_X=False, fit_intercept=False, n_jobs=None, positive=True\n",
      "[CV 2/2; 13/16] END copy_X=False, fit_intercept=False, n_jobs=None, positive=True;, score=0.482 total time=   0.1s\n",
      "[CV 1/2; 16/16] START copy_X=False, fit_intercept=False, n_jobs=-1, positive=False\n",
      "[CV 1/2; 16/16] END copy_X=False, fit_intercept=False, n_jobs=-1, positive=False;, score=0.301 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "linear_reg_model_valence.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b6ccb-cab6-49f6-a34c-15ed3ca7662a",
   "metadata": {},
   "source": [
    "# ---- Ridge regression ---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7316ce51-2f2d-4bb7-bd20-5580d44dccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 768 candidates, totalling 1536 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729346, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.58551489227125, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729355, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729346, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729352, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.58551489227284, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 1/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 1/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 3/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 3/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 4/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 4/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 6/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 6/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 7/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 7/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 9/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 9/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 11/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 11/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 13/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 13/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 16/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 16/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 16/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 16/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 21/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 21/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 21/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 21/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 25/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 25/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 25/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 25/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 26/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 26/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 26/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 26/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 37/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 37/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 37/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 37/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 38/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 38/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 38/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 38/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 39/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 39/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 39/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 39/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 40/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 2/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 2/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 5/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 5/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 7/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 7/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 9/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 9/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 11/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 11/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 12/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 12/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 14/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 14/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 18/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 18/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 18/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 18/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 22/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 22/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 22/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 22/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 27/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 27/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 27/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 27/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 28/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 28/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 28/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 28/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 33/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 33/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 33/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 33/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 34/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 34/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 34/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 34/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 43/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 43/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 43/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 43/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 44/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 44/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 44/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 1/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 1/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 3/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 3/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 4/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 4/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 5/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 5/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 6/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 6/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 8/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 8/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 10/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 10/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 12/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 12/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 14/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 14/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 17/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 17/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 17/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 17/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 20/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 20/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 20/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 20/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 29/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 29/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 29/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 29/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 30/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 30/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 30/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 30/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 35/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 35/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 35/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 35/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 36/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 36/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 36/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 36/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 51/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 51/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 51/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 2/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 2/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 8/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 8/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 10/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 10/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 13/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 13/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 15/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 15/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 15/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 15/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 19/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 19/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 19/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 19/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 23/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 23/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 23/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 23/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 24/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 24/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 24/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 24/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 31/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 31/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 31/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 31/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 32/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 32/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 32/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 32/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 47/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 47/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 47/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 47/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 48/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 48/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 48/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 48/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 49/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 49/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 49/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 49/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 50/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922725, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.58551489227204, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729346, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729352, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922725, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.58551489227204, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186.88600467595938, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.70921965953994, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 187.07596975781428, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.79154471546963, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186.89200797780848, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 187.02669601587525, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.74698345728677, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186.89200797780848, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 40/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 40/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 40/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 41/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 41/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 41/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 41/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 42/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 42/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 42/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 42/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 55/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 55/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 55/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 55/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 56/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 56/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 56/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 56/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.480 total time=   0.1s\n",
      "[CV 1/2; 57/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 57/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 57/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 57/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 58/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 58/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 58/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 58/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.480 total time=   0.1s\n",
      "[CV 1/2; 71/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 71/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.474 total time=   0.5s\n",
      "[CV 2/2; 71/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 71/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.480 total time=   0.6s\n",
      "[CV 1/2; 72/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 72/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.474 total time=   0.6s\n",
      "[CV 2/2; 72/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 72/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.480 total time=   0.6s\n",
      "[CV 1/2; 73/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 73/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 73/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 73/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.110 total time=   0.1s\n",
      "[CV 1/2; 74/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 74/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 74/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 74/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.110 total time=   0.1s\n",
      "[CV 1/2; 79/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 79/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.392 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.84683641124434, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.74698345728677, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 187.02669601587525, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.84683641124434, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 44/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 45/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 45/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 45/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 45/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 46/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 46/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 46/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 46/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 59/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 59/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 59/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 59/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 60/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 60/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 60/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 60/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 61/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 61/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 61/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 61/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.480 total time=   0.5s\n",
      "[CV 1/2; 62/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 62/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.474 total time=   0.5s\n",
      "[CV 2/2; 62/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 62/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.480 total time=   0.5s\n",
      "[CV 1/2; 75/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 75/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.391 total time=   0.1s\n",
      "[CV 2/2; 75/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 75/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.179 total time=   0.1s\n",
      "[CV 1/2; 76/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 76/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.392 total time=   0.2s\n",
      "[CV 2/2; 76/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 76/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.191 total time=   0.3s\n",
      "[CV 1/2; 77/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 77/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 77/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 77/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.110 total time=   0.2s\n",
      "[CV 1/2; 78/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 78/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.369 total time=   0.2s\n",
      "[CV 2/2; 78/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 78/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.110 total time=   0.2s\n",
      "[CV 1/2; 87/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 87/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.390 total time=   0.5s\n",
      "[CV 2/2; 87/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 87/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.188 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 50/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 50/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 50/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 63/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 63/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.474 total time=   0.4s\n",
      "[CV 2/2; 63/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 63/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.480 total time=   0.7s\n",
      "[CV 1/2; 64/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 64/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.474 total time=   0.5s\n",
      "[CV 2/2; 64/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 64/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.480 total time=   0.4s\n",
      "[CV 1/2; 65/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 65/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 65/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 65/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.480 total time=   0.4s\n",
      "[CV 1/2; 66/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 66/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 66/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 66/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.480 total time=   0.3s\n",
      "[CV 1/2; 83/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 83/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.392 total time=   0.1s\n",
      "[CV 2/2; 83/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 83/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.193 total time=   0.1s\n",
      "[CV 1/2; 84/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 84/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.392 total time=   0.1s\n",
      "[CV 2/2; 84/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 84/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.193 total time=   0.1s\n",
      "[CV 1/2; 85/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 85/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.369 total time=   0.3s\n",
      "[CV 2/2; 85/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 85/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.110 total time=   0.3s\n",
      "[CV 1/2; 86/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 86/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.369 total time=   0.4s\n",
      "[CV 2/2; 86/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 86/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.110 total time=   0.3s\n",
      "[CV 1/2; 99/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 99/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 99/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 99/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 100/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 100/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 100/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 100/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 101/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 101/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 101/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 101/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 102/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 102/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 102/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 102/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 103/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 103/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 103/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 103/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 104/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 104/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 104/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 104/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 105/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 105/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 105/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 105/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 106/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 106/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 106/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 106/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 107/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 107/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 107/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 107/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 108/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 108/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 108/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 108/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 109/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 109/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 109/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 109/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 110/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 110/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 110/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 110/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 111/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 111/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 111/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 111/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 112/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 112/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 112/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 112/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 113/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 113/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 113/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 113/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 114/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 114/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 114/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 114/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 115/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 115/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 115/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 115/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 116/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 116/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 116/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 116/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 117/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 117/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 117/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 117/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 118/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 118/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 118/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 118/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 119/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 119/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 119/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 119/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 120/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 120/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 120/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 120/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 121/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 121/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 121/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 121/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 122/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 122/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 122/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 122/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 123/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 123/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 123/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 123/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8537249907131, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 124/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 124/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 124/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 124/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 125/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 125/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 125/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 125/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 126/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 126/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 126/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 126/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 127/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 127/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 127/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 127/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 128/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 128/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 128/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 128/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 129/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 129/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 129/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 129/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 130/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 130/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 130/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 130/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 131/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 131/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 131/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 131/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 133/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 133/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 133/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 133/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 135/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 135/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 135/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 135/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 136/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 136/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 136/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 136/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 139/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 79/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 79/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.183 total time=   0.1s\n",
      "[CV 1/2; 80/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 80/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.392 total time=   0.1s\n",
      "[CV 2/2; 80/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 80/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.183 total time=   0.1s\n",
      "[CV 1/2; 81/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 81/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 81/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 81/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.110 total time=   0.1s\n",
      "[CV 1/2; 82/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 82/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 82/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 82/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.110 total time=   0.1s\n",
      "[CV 1/2; 95/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 95/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.392 total time=   0.4s\n",
      "[CV 2/2; 95/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 95/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.193 total time=   0.5s\n",
      "[CV 1/2; 96/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 96/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.392 total time=   0.6s\n",
      "[CV 2/2; 96/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 96/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.193 total time=   0.4s\n",
      "[CV 1/2; 97/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 97/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 97/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 97/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 98/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 98/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 98/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 98/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 132/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 132/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 132/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 132/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 134/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 134/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 134/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 134/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 137/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 137/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 137/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 137/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 138/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 138/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 138/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.9057458091411, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.85359740899, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.890293006054, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8547979251198, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.91190485633706, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 51/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 52/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 52/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 52/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 52/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 53/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 53/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 53/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 53/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 54/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 54/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 54/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 54/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 67/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 67/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.474 total time=   0.5s\n",
      "[CV 2/2; 67/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 67/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.480 total time=   0.7s\n",
      "[CV 1/2; 68/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 68/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.474 total time=   0.6s\n",
      "[CV 2/2; 68/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 68/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.480 total time=   0.5s\n",
      "[CV 1/2; 69/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 69/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.474 total time=   0.4s\n",
      "[CV 2/2; 69/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 69/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.480 total time=   0.4s\n",
      "[CV 1/2; 70/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 70/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 70/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 70/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.480 total time=   0.4s\n",
      "[CV 1/2; 91/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 91/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.392 total time=   0.4s\n",
      "[CV 2/2; 91/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 91/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.183 total time=   0.4s\n",
      "[CV 1/2; 92/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 92/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.392 total time=   0.3s\n",
      "[CV 2/2; 92/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 92/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.183 total time=   0.3s\n",
      "[CV 1/2; 93/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 93/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.369 total time=   0.3s\n",
      "[CV 2/2; 93/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 93/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.110 total time=   0.3s\n",
      "[CV 1/2; 94/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 94/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.369 total time=   0.3s\n",
      "[CV 2/2; 94/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 94/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.110 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8547979251198, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.85364248694896, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.8896647822585, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.91190485633706, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.85364248694896, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.8896647822585, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 139/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 139/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 139/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 140/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 140/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 140/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 140/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 143/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 143/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 143/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 143/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 144/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 144/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 144/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 144/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 147/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 147/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 147/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 147/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 148/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 148/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 148/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 148/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 151/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 151/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 151/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 151/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 152/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 152/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 152/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 152/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 153/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 153/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 153/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 153/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 154/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 154/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 154/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 154/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 167/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 167/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 167/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 167/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.483 total time=   0.3s\n",
      "[CV 1/2; 168/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 168/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.474 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.36724402291293, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193.8552053563726, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.62787263212886, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.72143076758584, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.58864991409064, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.88714645418804, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.58864991409064, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.88714645418804, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.66372503930688, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.73185235700294, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.66372503930688, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.73185235700294, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.953e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 138/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 141/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 141/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 141/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 141/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 142/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 142/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 142/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 142/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 145/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 145/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 145/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 145/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 146/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 146/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 146/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 146/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 149/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 149/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 149/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 149/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 150/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 150/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 150/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 150/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 163/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 163/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.474 total time=   0.2s\n",
      "[CV 2/2; 163/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 163/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.483 total time=   0.3s\n",
      "[CV 1/2; 164/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 164/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 164/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 164/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.483 total time=   0.3s\n",
      "[CV 1/2; 165/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 165/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.474 total time=   0.4s\n",
      "[CV 2/2; 165/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 165/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.482 total time=   0.4s\n",
      "[CV 1/2; 166/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 166/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 166/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 166/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.482 total time=   0.3s\n",
      "[CV 1/2; 183/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 183/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.426 total time=   0.3s\n",
      "[CV 1/2; 185/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 185/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.408 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 155/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 155/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 155/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 155/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 156/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 156/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 156/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 156/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 157/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 157/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 157/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 157/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.482 total time=   0.3s\n",
      "[CV 1/2; 158/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 158/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 158/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 158/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.482 total time=   0.3s\n",
      "[CV 1/2; 171/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 171/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.423 total time=   0.1s\n",
      "[CV 2/2; 171/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 171/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.327 total time=   0.1s\n",
      "[CV 1/2; 172/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 172/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.425 total time=   0.1s\n",
      "[CV 2/2; 172/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 172/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.333 total time=   0.1s\n",
      "[CV 1/2; 173/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 173/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 173/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 173/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 174/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 174/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 174/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 174/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 179/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 179/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.427 total time=   0.1s\n",
      "[CV 2/2; 179/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 179/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.334 total time=   0.1s\n",
      "[CV 1/2; 180/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 180/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.427 total time=   0.1s\n",
      "[CV 2/2; 180/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 180/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.334 total time=   0.1s\n",
      "[CV 1/2; 181/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 181/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.408 total time=   0.4s\n",
      "[CV 2/2; 181/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 181/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.307 total time=   0.6s\n",
      "[CV 1/2; 182/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.957e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.957e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 88/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 88/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.393 total time=   0.5s\n",
      "[CV 2/2; 88/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 88/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.190 total time=   0.5s\n",
      "[CV 1/2; 89/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 89/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.369 total time=   0.5s\n",
      "[CV 2/2; 89/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 89/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.110 total time=   0.4s\n",
      "[CV 1/2; 90/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 90/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.369 total time=   0.4s\n",
      "[CV 2/2; 90/768] START alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 90/768] END alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.110 total time=   0.3s\n",
      "[CV 1/2; 159/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 159/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.474 total time=   0.2s\n",
      "[CV 2/2; 159/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 159/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.483 total time=   0.3s\n",
      "[CV 1/2; 160/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 160/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 160/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 160/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.483 total time=   0.3s\n",
      "[CV 1/2; 161/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 161/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.474 total time=   0.4s\n",
      "[CV 2/2; 161/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 161/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.482 total time=   0.3s\n",
      "[CV 1/2; 162/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 162/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 162/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 162/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.482 total time=   0.3s\n",
      "[CV 2/2; 183/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 183/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.333 total time=   0.3s\n",
      "[CV 2/2; 184/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 184/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.324 total time=   0.3s\n",
      "[CV 1/2; 186/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 186/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.408 total time=   0.4s\n",
      "[CV 2/2; 187/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 187/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.336 total time=   0.5s\n",
      "[CV 1/2; 189/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 189/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.408 total time=   0.5s\n",
      "[CV 2/2; 190/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 190/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.307 total time=   0.4s\n",
      "[CV 1/2; 193/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 193/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 193/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 193/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 194/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 168/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 168/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.483 total time=   0.3s\n",
      "[CV 1/2; 169/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 169/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 169/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 169/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 170/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 170/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 170/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 170/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 175/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 175/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.428 total time=   0.1s\n",
      "[CV 2/2; 175/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 175/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.336 total time=   0.1s\n",
      "[CV 1/2; 176/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 176/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.428 total time=   0.1s\n",
      "[CV 2/2; 176/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 176/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.336 total time=   0.1s\n",
      "[CV 1/2; 177/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 177/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 177/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 177/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 178/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 178/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 178/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 178/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 184/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 184/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.423 total time=   0.3s\n",
      "[CV 2/2; 185/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 185/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.307 total time=   0.7s\n",
      "[CV 1/2; 188/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 188/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.428 total time=   0.4s\n",
      "[CV 2/2; 189/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 189/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.307 total time=   0.4s\n",
      "[CV 2/2; 191/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 191/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.334 total time=   0.4s\n",
      "[CV 2/2; 194/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 194/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 195/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 195/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 196/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 196/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 197/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 197/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 198/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 186/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 186/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.307 total time=   0.4s\n",
      "[CV 1/2; 187/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 187/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.428 total time=   0.4s\n",
      "[CV 2/2; 188/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 188/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.336 total time=   0.3s\n",
      "[CV 1/2; 190/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 190/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.408 total time=   0.4s\n",
      "[CV 1/2; 191/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 191/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.427 total time=   0.3s\n",
      "[CV 2/2; 192/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 192/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.334 total time=   0.3s\n",
      "[CV 1/2; 205/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 205/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 205/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 205/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 208/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 208/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 208/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 208/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 215/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 215/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 215/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 215/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 216/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 216/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 216/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 216/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 221/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 221/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 221/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 221/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 222/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 222/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 222/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 222/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 229/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 229/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 229/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 229/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 230/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 230/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 230/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 230/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 231/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 194/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 195/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 195/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 196/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 196/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 197/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 197/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 198/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 198/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 199/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 199/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 200/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 200/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 203/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 203/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 203/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 203/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 207/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 207/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 207/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 207/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 213/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 213/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 213/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 213/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 214/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 214/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 214/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 214/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 223/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 223/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 223/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 223/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 224/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 224/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 224/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 224/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 237/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 237/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 237/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 237/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 238/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 238/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 238/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 238/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 182/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.408 total time=   0.5s\n",
      "[CV 2/2; 182/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 182/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.307 total time=   0.4s\n",
      "[CV 1/2; 192/768] START alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 192/768] END alpha=0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.427 total time=   0.4s\n",
      "[CV 1/2; 200/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 200/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 202/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 202/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 202/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 202/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 206/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 206/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 206/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 206/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 211/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 211/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 211/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 211/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 212/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 212/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 212/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 212/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 219/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 219/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 219/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 219/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 220/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 220/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 220/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 220/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 233/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 233/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 233/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 233/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 234/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 234/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 234/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 234/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 235/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 235/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 235/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 235/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 236/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 236/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 198/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 199/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 199/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 201/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 201/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 201/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 201/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 204/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 204/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 204/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 204/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 209/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 209/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 209/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 209/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 210/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 210/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 210/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 210/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 217/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 217/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 217/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 217/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 218/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 218/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 218/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 218/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 225/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 225/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 225/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 225/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 226/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 226/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 226/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 226/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 227/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 227/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 227/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 227/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 228/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 228/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 228/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 228/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 245/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 245/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.474 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.85049097293404, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729354, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729346, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.58551489227193, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922725, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.85049097293495, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922715, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729346, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922726, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729352, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.5855148922725, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.58551489227204, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8504909729352, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.58551489227204, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186.93205613450198, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186.89200797780848, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.728932208488, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.74698345728677, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186.94113246838947, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186.89200797780848, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.73610340926052, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.74698345728677, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189.00264903177413, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183.01378846722992, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 187.02669601587525, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.84683641124434, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 187.02669601587525, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182.84683641124434, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 245/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 245/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 246/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 246/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 246/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 246/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 247/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 247/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 247/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 247/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 248/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 248/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 248/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 248/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 265/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 265/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 265/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 265/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.110 total time=   0.1s\n",
      "[CV 1/2; 266/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 266/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 266/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 266/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.110 total time=   0.1s\n",
      "[CV 1/2; 267/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 267/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.391 total time=   0.1s\n",
      "[CV 2/2; 267/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 267/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.175 total time=   0.1s\n",
      "[CV 1/2; 268/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 268/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.392 total time=   0.1s\n",
      "[CV 2/2; 268/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 268/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.197 total time=   0.1s\n",
      "[CV 1/2; 269/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 269/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 269/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 269/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.110 total time=   0.1s\n",
      "[CV 1/2; 270/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 270/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 270/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 270/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.110 total time=   0.1s\n",
      "[CV 1/2; 271/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 271/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.392 total time=   0.1s\n",
      "[CV 2/2; 271/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 271/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.183 total time=   0.1s\n",
      "[CV 1/2; 272/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 272/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.392 total time=   0.1s\n",
      "[CV 2/2; 272/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 239/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 239/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 239/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 239/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 240/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 240/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 240/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 240/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 249/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 249/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 249/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 249/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.480 total time=   0.1s\n",
      "[CV 1/2; 250/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 250/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.474 total time=   0.1s\n",
      "[CV 2/2; 250/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 250/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.480 total time=   0.1s\n",
      "[CV 1/2; 251/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 251/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 251/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 251/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.480 total time=   0.1s\n",
      "[CV 1/2; 252/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 252/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 252/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 252/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.480 total time=   0.1s\n",
      "[CV 1/2; 273/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 273/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 273/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 273/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.110 total time=   0.1s\n",
      "[CV 1/2; 274/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 274/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.369 total time=   0.1s\n",
      "[CV 2/2; 274/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 274/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.110 total time=   0.1s\n",
      "[CV 1/2; 275/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 275/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.392 total time=   0.1s\n",
      "[CV 2/2; 275/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 275/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.193 total time=   0.1s\n",
      "[CV 1/2; 276/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 276/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.392 total time=   0.1s\n",
      "[CV 2/2; 276/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 276/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.193 total time=   0.1s\n",
      "[CV 1/2; 277/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 277/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.369 total time=   0.4s\n",
      "[CV 2/2; 277/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 277/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.110 total time=   0.4s\n",
      "[CV 1/2; 278/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 236/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 236/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 253/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 253/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.474 total time=   0.2s\n",
      "[CV 2/2; 253/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 253/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.480 total time=   0.3s\n",
      "[CV 1/2; 254/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 254/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 254/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 254/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.480 total time=   0.4s\n",
      "[CV 1/2; 255/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 255/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 255/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 255/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.480 total time=   0.4s\n",
      "[CV 1/2; 256/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 256/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 256/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 256/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.480 total time=   0.3s\n",
      "[CV 1/2; 289/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 289/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 289/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 289/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 290/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 290/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 290/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 290/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 291/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 291/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 291/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 291/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 292/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 292/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 292/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 292/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 293/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 293/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 293/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 293/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 294/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 294/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 294/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 294/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 295/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 295/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 295/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 295/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 296/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 296/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 296/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 296/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 297/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 297/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 297/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 297/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 298/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 298/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 298/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 298/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 299/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 299/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 299/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 299/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 300/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 300/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 300/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 300/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 301/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 301/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 301/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 301/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 302/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 302/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 302/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 302/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 303/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 303/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 303/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 303/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 304/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 304/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 304/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 304/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 305/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 305/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 305/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 305/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 306/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 306/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 306/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 306/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 307/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 307/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 307/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 307/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 308/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 308/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 308/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 308/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 309/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 309/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 309/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 309/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 310/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 310/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 310/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 310/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 311/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 311/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 311/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 311/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 312/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 312/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 312/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 312/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 313/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 313/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 313/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 313/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 314/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 314/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 314/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 314/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 315/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 315/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 315/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 315/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 316/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 316/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 316/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 316/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 317/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 317/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 317/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 231/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 231/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 231/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 232/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 232/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 232/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 232/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 241/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 241/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 241/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 241/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 242/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 242/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 242/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 242/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 243/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 243/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 243/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 243/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 244/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 244/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 244/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 244/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.480 total time=   0.0s\n",
      "[CV 1/2; 257/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 257/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 257/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 257/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.480 total time=   0.3s\n",
      "[CV 1/2; 258/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 258/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 258/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 258/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.480 total time=   0.3s\n",
      "[CV 1/2; 259/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 259/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.474 total time=   0.2s\n",
      "[CV 2/2; 259/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 259/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.480 total time=   0.3s\n",
      "[CV 1/2; 260/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 260/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.474 total time=   0.4s\n",
      "[CV 2/2; 260/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 260/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.480 total time=   0.4s\n",
      "[CV 1/2; 261/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 261/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.474 total time=   0.4s\n",
      "[CV 2/2; 261/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 261/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.480 total time=   0.4s\n",
      "[CV 1/2; 262/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 317/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 318/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 318/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 318/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 318/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 319/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 319/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 319/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 319/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 320/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 320/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 320/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 320/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 321/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 321/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 321/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 321/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 322/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 322/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 322/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 322/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 323/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 323/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 323/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 323/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 324/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 324/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 324/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 324/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 325/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 325/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 325/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 325/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 326/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 326/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 326/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 326/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 327/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 327/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 327/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 327/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 328/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 328/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 328/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8550606210192, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.9093262983588, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.85382692442, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.8854300584353, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8547979251198, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.91190485633706, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8547979251198, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.91190485633706, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 328/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 329/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 329/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 329/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 329/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 330/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 330/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 330/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 330/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 331/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 331/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 331/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 331/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 332/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 332/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 332/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 332/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 333/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 333/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 333/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 333/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 334/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 334/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 334/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 334/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 335/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 335/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 335/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 335/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 336/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 336/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 336/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 336/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 337/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 337/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 337/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 337/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 338/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 338/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 338/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 338/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 340/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 340/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 340/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.8663158168929, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.85364248694896, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.88247889106424, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.8896647822585, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267.85364248694896, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263.8896647822585, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 278/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.369 total time=   0.5s\n",
      "[CV 2/2; 278/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 278/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.110 total time=   0.3s\n",
      "[CV 1/2; 279/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 279/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.392 total time=   0.3s\n",
      "[CV 2/2; 279/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 279/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.192 total time=   0.4s\n",
      "[CV 1/2; 280/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 280/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.391 total time=   0.3s\n",
      "[CV 2/2; 280/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 280/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.177 total time=   0.3s\n",
      "[CV 1/2; 339/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 339/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 339/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 339/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 341/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 341/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 341/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 341/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 343/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 343/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 343/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 343/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 345/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 345/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 345/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 345/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 347/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 347/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 347/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 347/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.483 total time=   0.1s\n",
      "[CV 1/2; 349/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 349/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 349/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 349/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.482 total time=   0.3s\n",
      "[CV 1/2; 352/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 352/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.474 total time=   0.2s\n",
      "[CV 2/2; 352/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 352/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.483 total time=   0.3s\n",
      "[CV 1/2; 355/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 355/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 355/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 355/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.483 total time=   0.3s\n",
      "[CV 1/2; 358/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.4568663576756, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.68337077590695, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.96752659440244, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.67095616080042, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.58864991409064, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+02, tolerance: 1.181e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.58864991409064, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.88714645418804, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.88714645418804, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.93194083446724, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.66372503930688, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.86514920465925, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+02, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.66372503930688, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.73185235700294, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.73185235700294, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 340/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 342/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 342/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 342/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 342/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 344/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 344/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 344/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 344/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 346/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 346/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 346/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 346/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.482 total time=   0.0s\n",
      "[CV 1/2; 348/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 348/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.474 total time=   0.0s\n",
      "[CV 2/2; 348/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 348/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.483 total time=   0.0s\n",
      "[CV 1/2; 350/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 350/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 350/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 350/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.482 total time=   0.3s\n",
      "[CV 1/2; 353/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 353/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 353/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 353/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.482 total time=   0.3s\n",
      "[CV 1/2; 356/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 356/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.474 total time=   0.2s\n",
      "[CV 2/2; 356/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 356/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.483 total time=   0.2s\n",
      "[CV 1/2; 357/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 357/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 357/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 357/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.482 total time=   0.3s\n",
      "[CV 1/2; 360/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 360/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 360/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 360/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.483 total time=   0.3s\n",
      "[CV 1/2; 366/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 366/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 366/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 366/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 369/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 369/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 369/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 262/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 262/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 262/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.480 total time=   0.3s\n",
      "[CV 1/2; 263/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 263/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.474 total time=   0.2s\n",
      "[CV 2/2; 263/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 263/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.480 total time=   0.2s\n",
      "[CV 1/2; 264/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 264/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.474 total time=   0.4s\n",
      "[CV 2/2; 264/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 264/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.480 total time=   0.4s\n",
      "[CV 1/2; 351/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 351/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.474 total time=   0.2s\n",
      "[CV 2/2; 351/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 351/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.483 total time=   0.2s\n",
      "[CV 1/2; 354/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 354/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 354/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 354/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.482 total time=   0.4s\n",
      "[CV 1/2; 359/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 359/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 359/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 359/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.483 total time=   0.4s\n",
      "[CV 1/2; 362/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 362/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 362/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 362/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.307 total time=   0.2s\n",
      "[CV 1/2; 364/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 364/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.422 total time=   0.1s\n",
      "[CV 2/2; 364/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 364/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.339 total time=   0.1s\n",
      "[CV 1/2; 367/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 367/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.428 total time=   0.1s\n",
      "[CV 2/2; 367/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 367/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.336 total time=   0.1s\n",
      "[CV 1/2; 370/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 370/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 370/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 370/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 373/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 373/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.408 total time=   0.3s\n",
      "[CV 2/2; 373/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 373/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.307 total time=   0.3s\n",
      "[CV 1/2; 378/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.957e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.957e+02, tolerance: 2.129e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 272/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.183 total time=   0.1s\n",
      "[CV 1/2; 281/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 281/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.369 total time=   0.4s\n",
      "[CV 2/2; 281/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 281/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.110 total time=   0.4s\n",
      "[CV 1/2; 282/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 282/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.369 total time=   0.4s\n",
      "[CV 2/2; 282/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 282/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.110 total time=   0.3s\n",
      "[CV 1/2; 283/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 283/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.392 total time=   0.4s\n",
      "[CV 2/2; 283/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 283/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.183 total time=   0.3s\n",
      "[CV 1/2; 284/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 284/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.392 total time=   0.3s\n",
      "[CV 2/2; 284/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 284/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.183 total time=   0.4s\n",
      "[CV 1/2; 285/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 285/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.369 total time=   0.4s\n",
      "[CV 2/2; 285/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 285/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.110 total time=   0.5s\n",
      "[CV 1/2; 286/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 286/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.369 total time=   0.4s\n",
      "[CV 2/2; 286/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 286/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.110 total time=   0.4s\n",
      "[CV 1/2; 287/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 287/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.392 total time=   0.4s\n",
      "[CV 2/2; 287/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 287/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.193 total time=   0.3s\n",
      "[CV 1/2; 288/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 288/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.392 total time=   0.2s\n",
      "[CV 2/2; 288/768] START alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 288/768] END alpha=0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.193 total time=   0.3s\n",
      "[CV 1/2; 374/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 374/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.408 total time=   0.3s\n",
      "[CV 2/2; 374/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 374/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.307 total time=   0.3s\n",
      "[CV 1/2; 377/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 377/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.408 total time=   0.3s\n",
      "[CV 2/2; 377/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 377/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.307 total time=   0.4s\n",
      "[CV 1/2; 381/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 381/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.408 total time=   0.4s\n",
      "[CV 2/2; 381/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+02, tolerance: 2.149e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 358/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.474 total time=   0.3s\n",
      "[CV 2/2; 358/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 358/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.482 total time=   0.3s\n",
      "[CV 1/2; 361/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 361/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.408 total time=   0.2s\n",
      "[CV 2/2; 361/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 361/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 363/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 363/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.420 total time=   0.1s\n",
      "[CV 2/2; 363/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 363/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.371 total time=   0.1s\n",
      "[CV 1/2; 365/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 365/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.408 total time=   0.1s\n",
      "[CV 2/2; 365/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 365/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 368/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 368/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.428 total time=   0.1s\n",
      "[CV 2/2; 368/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 368/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.336 total time=   0.1s\n",
      "[CV 1/2; 371/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 371/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.427 total time=   0.1s\n",
      "[CV 2/2; 371/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 371/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.334 total time=   0.1s\n",
      "[CV 1/2; 375/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 375/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.428 total time=   0.4s\n",
      "[CV 2/2; 375/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 375/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.303 total time=   0.4s\n",
      "[CV 1/2; 379/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 379/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.428 total time=   0.4s\n",
      "[CV 2/2; 379/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 379/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.336 total time=   0.3s\n",
      "[CV 1/2; 383/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 383/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.427 total time=   0.3s\n",
      "[CV 2/2; 383/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 383/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.334 total time=   0.3s\n",
      "[CV 1/2; 389/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 389/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 389/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 389/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 392/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 392/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 392/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 392/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 394/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 381/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.307 total time=   0.3s\n",
      "[CV 1/2; 385/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 385/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 385/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 385/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 386/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 386/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 386/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 386/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 387/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 387/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 387/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 387/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 388/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 388/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 388/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 388/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 390/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 390/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 390/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 390/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 393/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 393/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 393/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 393/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 396/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 396/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 396/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 396/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 400/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 400/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 400/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 400/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 404/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 404/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 404/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 404/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 408/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 408/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 408/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 408/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 412/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 412/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 412/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 369/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.307 total time=   0.1s\n",
      "[CV 1/2; 372/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 372/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.427 total time=   0.1s\n",
      "[CV 2/2; 372/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 372/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.334 total time=   0.1s\n",
      "[CV 1/2; 376/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 376/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.419 total time=   0.4s\n",
      "[CV 2/2; 376/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 376/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.303 total time=   0.4s\n",
      "[CV 1/2; 380/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 380/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.428 total time=   0.3s\n",
      "[CV 2/2; 380/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 380/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.336 total time=   0.3s\n",
      "[CV 1/2; 384/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 384/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.427 total time=   0.4s\n",
      "[CV 2/2; 384/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 384/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.334 total time=   0.4s\n",
      "[CV 1/2; 402/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 402/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 402/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 402/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 406/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 406/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 406/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 406/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 410/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 410/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 410/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 410/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 415/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 415/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 415/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 415/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 416/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 416/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 416/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 416/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 421/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 421/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 421/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 421/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 422/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 422/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 422/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 378/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.408 total time=   0.4s\n",
      "[CV 2/2; 378/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 378/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.307 total time=   0.4s\n",
      "[CV 1/2; 382/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 382/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.408 total time=   0.4s\n",
      "[CV 2/2; 382/768] START alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 382/768] END alpha=0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.307 total time=   0.4s\n",
      "[CV 1/2; 391/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 391/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 391/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 391/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 395/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 395/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 395/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 395/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 398/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 398/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 398/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 398/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 401/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 401/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 401/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 401/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 405/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 405/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 405/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 405/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 409/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 409/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 409/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 409/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 413/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 413/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 413/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 413/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 414/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 414/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 414/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 414/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 425/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 425/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 425/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 425/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 426/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 426/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 394/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 394/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 394/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 397/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 397/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 397/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 397/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 399/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 399/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 399/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 399/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 403/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 403/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 403/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 403/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 407/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 407/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 407/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 407/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 411/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 411/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 411/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 411/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 417/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 417/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 417/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 417/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 418/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 418/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 418/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 418/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 423/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 423/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 423/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 423/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 424/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 424/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 424/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 424/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 433/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 433/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 433/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 433/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 434/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 394.44256952773037, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 384.2470940697012, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 381.1845342006564, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 393.1709788476556, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 412/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 419/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 419/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 419/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 419/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 420/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 420/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 420/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 420/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 427/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 427/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 427/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 427/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 428/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 428/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 428/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 428/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 441/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 441/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 441/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 441/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 442/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 442/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 442/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 442/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 443/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 443/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 443/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 443/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 444/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 444/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 444/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 444/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 453/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 453/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 453/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 453/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 454/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 454/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 454/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 454/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 455/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 455/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 455/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 455/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 2/2; 422/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 429/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 429/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 429/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 429/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 430/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 430/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 430/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 430/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 431/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 431/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 431/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 431/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 432/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 432/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 432/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 432/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 445/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 445/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 445/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 445/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 446/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 446/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 446/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 446/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 447/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 447/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 447/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 447/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 448/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 448/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 448/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 448/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 461/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 461/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 461/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 461/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 462/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 462/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 462/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 462/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 463/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 463/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 463/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 384.1414399625855, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.2869744135068, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 393.1709788476556, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 384.1414399625855, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 426/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 426/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 437/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 437/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 437/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 437/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 438/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 438/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 438/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 438/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 439/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 439/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 439/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 439/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 440/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 440/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 440/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 440/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 457/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 457/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 457/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 457/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 458/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 458/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 458/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 458/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 459/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 459/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 459/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 459/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 460/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 460/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 460/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 460/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.324 total time=   0.1s\n",
      "[CV 1/2; 485/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 485/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 485/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 485/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 486/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 486/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 486/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 486/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 487/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 487/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 381.35086883339324, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 381.8794707895469, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 381.35086883339324, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 381.8794707895469, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 487/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 487/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 488/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 488/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 488/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 488/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 489/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 489/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 489/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 489/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 490/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 490/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 490/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 490/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 491/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 491/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 491/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 491/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 492/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 492/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 492/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 492/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 493/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 493/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 493/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 493/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 494/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 494/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 494/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 494/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 495/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 495/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 495/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 495/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 496/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 496/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 496/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 496/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 497/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 497/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 497/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 497/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 498/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 498/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 463/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 464/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 464/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 464/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 464/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 465/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 465/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 465/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 465/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 466/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 466/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 466/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 466/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 467/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 467/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 467/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 467/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 468/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 468/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 468/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 468/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 501/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 501/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 501/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 501/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 502/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 502/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 502/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 502/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 503/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 503/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 503/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 503/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 504/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 504/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 504/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 504/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 505/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 505/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 505/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 505/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 506/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 506/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 506/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.933e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.814e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 506/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 507/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 507/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 507/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 507/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 508/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 508/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 508/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 508/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 517/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 517/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 517/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 517/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 518/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 518/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 518/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 518/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 519/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 519/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 519/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 519/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 520/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 520/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 520/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 520/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 521/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 521/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 521/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 521/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 522/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 522/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 522/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 522/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 523/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 523/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 523/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 523/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 524/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 524/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 524/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 524/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 525/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 525/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 525/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 498/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 498/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 499/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 499/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 499/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 499/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 500/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 500/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 500/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 500/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 509/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 509/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 509/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 509/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 510/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 510/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 510/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 510/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 511/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 511/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 511/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 511/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 512/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 512/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 512/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 512/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 513/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 513/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 513/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 513/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 514/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 514/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 514/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 514/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 515/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 515/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 515/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 515/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 516/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 516/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 516/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 516/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 533/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 533/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.0s\n",
      "[CV 2/2; 533/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.737e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.819e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.894e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.814e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.843e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.819e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 541.4040588996673, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 548.43508774287, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 434/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 434/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 434/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 435/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 435/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 435/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 435/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 436/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 436/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 436/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 436/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 449/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 449/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 449/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 449/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 450/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 450/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 450/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 450/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 451/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 451/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 451/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 451/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 452/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 452/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 452/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 452/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 469/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 469/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 469/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 469/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 470/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 470/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 470/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 470/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 471/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 471/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.322 total time=   0.2s\n",
      "[CV 2/2; 471/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 471/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.324 total time=   0.2s\n",
      "[CV 1/2; 472/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 472/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.322 total time=   0.2s\n",
      "[CV 2/2; 472/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 472/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.324 total time=   0.2s\n",
      "[CV 1/2; 473/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 525/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 526/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 526/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 526/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 526/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 527/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 527/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 527/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 527/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 528/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 528/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 528/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 528/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 529/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 529/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.0s\n",
      "[CV 2/2; 529/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 529/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 530/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 530/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.0s\n",
      "[CV 2/2; 530/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 530/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 531/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 531/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=-0.057 total time=   0.0s\n",
      "[CV 2/2; 531/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 531/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 532/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 532/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=-0.057 total time=   0.0s\n",
      "[CV 2/2; 532/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 532/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 541/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 541/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 541/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 541/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 542/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 542/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 542/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 542/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 543/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 543/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=-0.057 total time=   0.1s\n",
      "[CV 2/2; 543/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 543/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 544/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 544/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=-0.057 total time=   0.1s\n",
      "[CV 2/2; 544/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 456/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 456/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 456/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 456/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 477/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 477/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 477/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 477/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 478/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 478/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 478/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 478/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 479/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 479/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.322 total time=   0.2s\n",
      "[CV 2/2; 479/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 479/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.324 total time=   0.2s\n",
      "[CV 1/2; 480/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 480/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.322 total time=   0.2s\n",
      "[CV 2/2; 480/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 480/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.324 total time=   0.2s\n",
      "[CV 1/2; 481/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 481/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 481/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 481/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 482/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 482/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 482/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 482/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 483/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 483/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 483/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 483/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 484/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 484/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 484/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 484/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 557/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 557/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.063 total time=   0.1s\n",
      "[CV 2/2; 557/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 557/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.173 total time=   0.0s\n",
      "[CV 1/2; 558/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 558/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.063 total time=   0.0s\n",
      "[CV 2/2; 558/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 558/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.173 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 541.4040588996673, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 548.43508774287, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 533/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 534/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 534/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.0s\n",
      "[CV 2/2; 534/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 534/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 535/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 535/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=-0.057 total time=   0.0s\n",
      "[CV 2/2; 535/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 535/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=-0.059 total time=   0.0s\n",
      "[CV 1/2; 536/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 536/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=-0.057 total time=   0.0s\n",
      "[CV 2/2; 536/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 536/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=-0.059 total time=   0.0s\n",
      "[CV 1/2; 537/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 537/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.0s\n",
      "[CV 2/2; 537/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 537/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 538/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 538/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.0s\n",
      "[CV 2/2; 538/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 538/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 539/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 539/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=-0.056 total time=   0.0s\n",
      "[CV 2/2; 539/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 539/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 540/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 540/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=-0.056 total time=   0.0s\n",
      "[CV 2/2; 540/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 540/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 549/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 549/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 549/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 549/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 550/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 550/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 550/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 550/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 551/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 551/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=-0.056 total time=   0.1s\n",
      "[CV 2/2; 551/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 551/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 552/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 552/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=-0.056 total time=   0.1s\n",
      "[CV 2/2; 552/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 542.4809032323699, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 547.6667998969945, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 542.4210715192803, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 544.3371384641921, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 546.8191070494747, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 550.068461197811, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 542.4210715192803, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 546.8191070494747, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 559/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 559/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.143 total time=   0.0s\n",
      "[CV 2/2; 559/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 559/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.187 total time=   0.0s\n",
      "[CV 1/2; 560/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 560/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.143 total time=   0.0s\n",
      "[CV 2/2; 560/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 560/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.187 total time=   0.1s\n",
      "[CV 1/2; 561/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 561/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.063 total time=   0.0s\n",
      "[CV 2/2; 561/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 561/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.173 total time=   0.0s\n",
      "[CV 1/2; 562/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 562/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.063 total time=   0.0s\n",
      "[CV 2/2; 562/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 562/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.173 total time=   0.0s\n",
      "[CV 1/2; 563/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 563/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.147 total time=   0.0s\n",
      "[CV 2/2; 563/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 563/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.189 total time=   0.0s\n",
      "[CV 1/2; 564/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 564/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.147 total time=   0.0s\n",
      "[CV 2/2; 564/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 564/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.189 total time=   0.1s\n",
      "[CV 1/2; 581/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 581/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 581/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 581/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 582/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 582/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 582/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 582/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 583/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 583/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 583/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 583/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 584/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 584/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 584/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 584/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 585/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 585/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 585/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 585/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 586/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.932e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.841e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.932e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 586/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 586/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 586/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 587/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 587/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 587/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 587/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 588/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 588/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 588/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 588/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 589/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 589/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 589/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 589/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 590/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 590/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 590/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 590/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 591/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 591/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 591/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 591/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 592/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 592/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 592/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 592/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 593/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 593/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 593/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 593/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 594/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 594/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 594/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 594/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 595/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 595/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 595/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 595/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 596/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 596/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 596/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 596/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 597/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.841e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.422e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 597/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 597/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 597/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 598/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 598/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 598/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 598/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 599/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 599/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 599/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 599/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 600/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 600/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 600/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 600/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 601/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 601/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 601/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 601/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 602/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 602/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 602/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 602/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 603/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 603/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 603/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 603/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 604/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 604/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 604/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 604/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 605/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 605/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 605/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 605/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 606/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 606/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 606/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 606/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 607/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 607/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 607/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 607/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 608/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 473/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 473/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 473/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 474/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 474/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 474/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 474/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 475/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 475/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.322 total time=   0.3s\n",
      "[CV 2/2; 475/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 475/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.324 total time=   0.2s\n",
      "[CV 1/2; 476/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 476/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.322 total time=   0.2s\n",
      "[CV 2/2; 476/768] START alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 476/768] END alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.324 total time=   0.2s\n",
      "[CV 1/2; 613/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 613/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 613/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 613/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 614/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 614/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 614/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 614/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 615/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 615/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 615/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 615/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 616/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 616/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 616/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 616/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 617/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 617/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 617/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 617/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 618/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 618/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 618/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 618/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 619/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 619/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 619/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 619/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 620/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.424e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.490e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.468e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.457e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.424e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.479e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 608/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 608/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 608/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 609/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 609/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 609/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 609/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 610/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 610/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 610/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 610/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 611/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 611/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 611/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 611/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 612/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 612/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 612/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 612/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 629/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 629/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 629/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 629/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 630/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 630/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 630/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 630/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 631/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 631/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 631/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 631/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 632/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 632/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 632/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 632/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 633/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 633/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 633/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 633/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 634/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 634/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 634/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 634/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 635/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 620/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 620/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 620/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 621/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 621/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 621/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 621/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 622/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 622/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 622/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 622/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 623/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 623/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 623/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 623/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 624/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 624/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 624/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 624/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 625/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 625/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 625/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 625/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 626/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 626/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 626/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 626/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 627/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 627/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 627/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 627/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 628/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 628/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 628/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 628/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 637/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 637/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 637/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 637/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 638/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 638/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 638/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 638/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 639/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 552/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 553/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 553/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.063 total time=   0.0s\n",
      "[CV 2/2; 553/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 553/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.173 total time=   0.0s\n",
      "[CV 1/2; 554/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 554/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.063 total time=   0.0s\n",
      "[CV 2/2; 554/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 554/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.173 total time=   0.0s\n",
      "[CV 1/2; 555/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 555/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.146 total time=   0.0s\n",
      "[CV 2/2; 555/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 555/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.188 total time=   0.0s\n",
      "[CV 1/2; 556/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 556/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.145 total time=   0.0s\n",
      "[CV 2/2; 556/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 556/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.183 total time=   0.0s\n",
      "[CV 1/2; 573/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 573/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.063 total time=   0.2s\n",
      "[CV 2/2; 573/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 573/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.173 total time=   0.2s\n",
      "[CV 1/2; 574/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 574/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.063 total time=   0.2s\n",
      "[CV 2/2; 574/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 574/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.173 total time=   0.2s\n",
      "[CV 1/2; 575/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 575/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.147 total time=   0.2s\n",
      "[CV 2/2; 575/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 575/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.189 total time=   0.2s\n",
      "[CV 1/2; 576/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 576/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.147 total time=   0.2s\n",
      "[CV 2/2; 576/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 576/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.189 total time=   0.2s\n",
      "[CV 1/2; 577/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 577/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 577/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 577/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 578/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 578/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 578/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 578/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 579/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 579/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 579/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.468e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 393.1709788476556, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 384.1414399625855, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 393.1709788476556, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 394.5368166292289, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 384.1414399625855, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 383.63414257919436, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 394.7897064365104, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 384.08695980611935, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382.9519423061329, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 378.9499218443723, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 381.35086883339324, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 381.8794707895469, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 381.35086883339324, tolerance: 0.11807284444970413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 381.8794707895469, tolerance: 0.11453066350295862\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.414e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 579/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 580/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 580/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 580/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 580/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 653/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 653/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 653/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 653/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 654/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 654/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 654/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 654/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 655/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 655/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 655/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 655/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 656/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 656/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 656/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 656/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 657/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 657/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 657/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 657/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 658/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 658/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 658/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 658/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 659/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 659/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 659/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 659/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 660/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 660/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 660/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 660/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 677/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 677/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 677/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 677/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 678/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 678/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 678/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 544/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 545/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 545/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 545/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 545/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 546/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 546/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 546/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 546/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 547/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 547/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=-0.057 total time=   0.1s\n",
      "[CV 2/2; 547/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 547/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=-0.059 total time=   0.0s\n",
      "[CV 1/2; 548/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 548/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=-0.057 total time=   0.0s\n",
      "[CV 2/2; 548/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 548/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=-0.059 total time=   0.0s\n",
      "[CV 1/2; 565/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 565/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.063 total time=   0.2s\n",
      "[CV 2/2; 565/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 565/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.173 total time=   0.2s\n",
      "[CV 1/2; 566/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 566/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.063 total time=   0.2s\n",
      "[CV 2/2; 566/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 566/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.173 total time=   0.2s\n",
      "[CV 1/2; 567/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 567/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.146 total time=   0.2s\n",
      "[CV 2/2; 567/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 567/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.187 total time=   0.2s\n",
      "[CV 1/2; 568/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 568/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.143 total time=   0.2s\n",
      "[CV 2/2; 568/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 568/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.185 total time=   0.2s\n",
      "[CV 1/2; 569/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 569/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.063 total time=   0.2s\n",
      "[CV 2/2; 569/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 569/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.173 total time=   0.2s\n",
      "[CV 1/2; 570/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 570/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.063 total time=   0.2s\n",
      "[CV 2/2; 570/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 570/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.173 total time=   0.2s\n",
      "[CV 1/2; 571/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 571/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.143 total time=   0.2s\n",
      "[CV 2/2; 571/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.484e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.414e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 678/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 679/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 679/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 679/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 679/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 680/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 680/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 680/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 680/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 681/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 681/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 681/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 681/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 682/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 682/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 682/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 682/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 683/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 683/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 683/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 683/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 684/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 684/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 684/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 684/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 685/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 685/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 685/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 685/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 686/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 686/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 686/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 686/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 687/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 687/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 687/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 687/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 688/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 688/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 688/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 688/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 689/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 689/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 689/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 635/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 635/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 635/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 636/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 636/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 636/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 636/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 645/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 645/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 645/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 645/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 646/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 646/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 646/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 646/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 647/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 647/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 647/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 647/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 648/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 648/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 648/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 648/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 649/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 649/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 649/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 649/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 650/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 650/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.323 total time=   0.0s\n",
      "[CV 2/2; 650/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 650/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=0.327 total time=   0.0s\n",
      "[CV 1/2; 651/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 651/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 651/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 651/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 652/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 652/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.322 total time=   0.0s\n",
      "[CV 2/2; 652/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 652/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=0.324 total time=   0.0s\n",
      "[CV 1/2; 669/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 669/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 669/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 669/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 670/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.953e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.484e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.840e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.921e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.814e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 689/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 690/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 690/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 690/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 690/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 691/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 691/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 691/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 691/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 692/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 692/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 692/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 692/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 693/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 693/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 693/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 693/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 694/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 694/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 694/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 694/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 695/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 695/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 695/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 695/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 696/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 696/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 696/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 696/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 697/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 697/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 697/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 697/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 698/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 698/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 698/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 698/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 699/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 699/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 699/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 699/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 700/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 700/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 700/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 571/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.187 total time=   0.2s\n",
      "[CV 1/2; 572/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 572/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.143 total time=   0.2s\n",
      "[CV 2/2; 572/768] START alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 572/768] END alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.187 total time=   0.2s\n",
      "[CV 1/2; 701/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 701/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 701/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 701/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 702/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 702/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 702/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 702/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 703/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 703/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 703/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 703/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 704/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 704/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 704/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 704/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 705/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 705/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 705/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 705/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 706/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 706/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 706/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 706/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 707/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 707/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 707/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 707/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 708/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 708/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 708/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 708/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 717/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 717/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 717/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 717/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 718/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 718/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 718/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.819e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 700/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 709/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 709/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 709/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 709/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 710/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 710/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 710/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 710/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 711/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 711/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 711/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 711/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 712/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 712/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 712/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 712/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 713/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 713/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 713/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 713/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 714/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 714/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 714/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 714/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 715/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 715/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 715/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 715/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 716/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 716/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 716/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 716/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=3, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 725/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 725/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.0s\n",
      "[CV 2/2; 725/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 725/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 726/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 726/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.0s\n",
      "[CV 2/2; 726/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 726/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 727/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 727/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=-0.057 total time=   0.0s\n",
      "[CV 2/2; 727/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.814e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.819e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 639/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 639/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 639/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 640/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 640/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 640/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 640/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 641/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 641/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 641/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 641/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 642/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 642/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 642/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 642/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 643/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 643/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 643/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 643/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=True;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 644/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 644/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.236 total time=   0.0s\n",
      "[CV 2/2; 644/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 644/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=True, precompute=False, random_state=3, selection=random, warm_start=False;, score=0.220 total time=   0.0s\n",
      "[CV 1/2; 661/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 661/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 661/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 661/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 662/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 662/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 662/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 662/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 663/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 663/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.322 total time=   0.2s\n",
      "[CV 2/2; 663/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 663/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=True;, score=0.324 total time=   0.2s\n",
      "[CV 1/2; 664/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 664/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.322 total time=   0.2s\n",
      "[CV 2/2; 664/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 664/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=None, selection=random, warm_start=False;, score=0.324 total time=   0.2s\n",
      "[CV 1/2; 665/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 665/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 665/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 665/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 666/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=3, selection=cyclic, warm_start=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 541.4040588996673, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 548.43508774287, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 541.4040588996673, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.932e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 548.43508774287, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 718/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 719/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 719/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 719/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 719/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 720/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 720/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 720/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 720/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 721/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 721/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.0s\n",
      "[CV 2/2; 721/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 721/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 722/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 722/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.0s\n",
      "[CV 2/2; 722/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 722/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 723/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 723/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=-0.057 total time=   0.0s\n",
      "[CV 2/2; 723/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 723/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 724/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 724/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=-0.057 total time=   0.1s\n",
      "[CV 2/2; 724/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 724/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 733/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 733/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.2s\n",
      "[CV 2/2; 733/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 733/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 734/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 734/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 734/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 734/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 735/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 735/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=-0.056 total time=   0.1s\n",
      "[CV 2/2; 735/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 735/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 736/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 736/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=-0.057 total time=   0.0s\n",
      "[CV 2/2; 736/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 736/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=None, selection=random, warm_start=False;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 737/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 737/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 737/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 727/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=True;, score=-0.059 total time=   0.0s\n",
      "[CV 1/2; 728/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 728/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=-0.057 total time=   0.0s\n",
      "[CV 2/2; 728/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 728/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=3, selection=random, warm_start=False;, score=-0.059 total time=   0.0s\n",
      "[CV 1/2; 729/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 729/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 729/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 729/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 730/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 730/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 730/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 730/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 731/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 731/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=-0.056 total time=   0.0s\n",
      "[CV 2/2; 731/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 731/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=True;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 732/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 732/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=-0.056 total time=   0.1s\n",
      "[CV 2/2; 732/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 732/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=True, random_state=5, selection=random, warm_start=False;, score=-0.060 total time=   0.0s\n",
      "[CV 1/2; 749/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 749/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.063 total time=   0.1s\n",
      "[CV 2/2; 749/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 749/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=True;, score=0.173 total time=   0.0s\n",
      "[CV 1/2; 750/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 750/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.063 total time=   0.0s\n",
      "[CV 2/2; 750/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 750/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=cyclic, warm_start=False;, score=0.173 total time=   0.0s\n",
      "[CV 1/2; 751/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 1/2; 751/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.143 total time=   0.0s\n",
      "[CV 2/2; 751/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True\n",
      "[CV 2/2; 751/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=True;, score=0.187 total time=   0.0s\n",
      "[CV 1/2; 752/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 1/2; 752/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.143 total time=   0.0s\n",
      "[CV 2/2; 752/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False\n",
      "[CV 2/2; 752/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=3, selection=random, warm_start=False;, score=0.187 total time=   0.0s\n",
      "[CV 1/2; 753/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 753/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.063 total time=   0.0s\n",
      "[CV 2/2; 753/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 753/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=True;, score=0.173 total time=   0.0s\n",
      "[CV 1/2; 754/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 754/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False;, score=0.063 total time=   0.0s\n",
      "[CV 2/2; 754/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 670/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.323 total time=   0.2s\n",
      "[CV 2/2; 670/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 670/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=0.327 total time=   0.2s\n",
      "[CV 1/2; 671/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 671/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.322 total time=   0.2s\n",
      "[CV 2/2; 671/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 671/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=True;, score=0.324 total time=   0.2s\n",
      "[CV 1/2; 672/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 672/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.322 total time=   0.2s\n",
      "[CV 2/2; 672/768] START alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 672/768] END alpha=1.0, copy_X=False, fit_intercept=True, max_iter=1000, positive=False, precompute=False, random_state=5, selection=random, warm_start=False;, score=0.324 total time=   0.2s\n",
      "[CV 1/2; 673/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 673/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 673/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 673/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 674/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 674/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 674/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 674/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=cyclic, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 675/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 1/2; 675/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 2/2; 675/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True\n",
      "[CV 2/2; 675/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=True;, score=nan total time=   0.0s\n",
      "[CV 1/2; 676/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 1/2; 676/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 2/2; 676/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False\n",
      "[CV 2/2; 676/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=None, positive=True, precompute=True, random_state=None, selection=random, warm_start=False;, score=nan total time=   0.0s\n",
      "[CV 1/2; 741/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 1/2; 741/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 741/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True\n",
      "[CV 2/2; 741/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=True;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 742/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 1/2; 742/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=-0.058 total time=   0.1s\n",
      "[CV 2/2; 742/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False\n",
      "[CV 2/2; 742/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=cyclic, warm_start=False;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 743/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 1/2; 743/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=-0.056 total time=   0.1s\n",
      "[CV 2/2; 743/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True\n",
      "[CV 2/2; 743/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=True;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 744/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 1/2; 744/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=-0.056 total time=   0.1s\n",
      "[CV 2/2; 744/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False\n",
      "[CV 2/2; 744/768] END alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=True, precompute=False, random_state=5, selection=random, warm_start=False;, score=-0.060 total time=   0.1s\n",
      "[CV 1/2; 745/768] START alpha=1.0, copy_X=False, fit_intercept=False, max_iter=1000, positive=False, precompute=True, random_state=None, selection=cyclic, warm_start=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.841e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 542.4210715192803, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 546.8191070494747, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8709436210486, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 542.4210715192803, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 565.7658211266927, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.932e+02, tolerance: 1.181e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 546.8191070494747, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 541.2104649258489, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 548.5071642532482, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 543.4216437534801, tolerance: 2.129384489999999\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 546.3967425330595, tolerance: 2.1486907400000006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.841e+02, tolerance: 1.145e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.438e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.497e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.419e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.465e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.414e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.484e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.414e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.484e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.658e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.424e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.468e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.468e+02, tolerance: 2.149e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.424e+02, tolerance: 2.129e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "768 fits failed out of a total of 1536.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "384 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 1004, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "                                             ^^^^^^^^^^\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 617, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent_gram(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"sklearn/linear_model/_cd_fast.pyx\", line 576, in sklearn.linear_model._cd_fast.enet_coordinate_descent_gram\n",
      "TypeError: an integer is required\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "384 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 1004, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "                                             ^^^^^^^^^^\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 631, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"sklearn/linear_model/_cd_fast.pyx\", line 100, in sklearn.linear_model._cd_fast.enet_coordinate_descent\n",
      "TypeError: an integer is required\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742\n",
      "  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742\n",
      "  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742\n",
      "  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742\n",
      "  0.23952333  0.23952333  0.28530192  0.29187852  0.23952333  0.23952333\n",
      "  0.28705582  0.28705582  0.23952333  0.23952333  0.29234946  0.29234946\n",
      "  0.23952333  0.23952333  0.28896343  0.29141451  0.23952333  0.23952333\n",
      "  0.28705582  0.28705582  0.23952333  0.23952333  0.29234946  0.29234946\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.47818842  0.47818842  0.47869542  0.47852608  0.47818842  0.47818842\n",
      "  0.4787548   0.4787548   0.47818842  0.47818842  0.47847704  0.47847704\n",
      "  0.47818842  0.47818842  0.47838454  0.47869415  0.47818842  0.47818842\n",
      "  0.4787548   0.4787548   0.47818842  0.47818842  0.47847704  0.47847704\n",
      "  0.35761176  0.35761176  0.375191    0.37898588  0.35761176  0.35761176\n",
      "  0.38239401  0.38239401  0.35761176  0.35761176  0.38051511  0.38051511\n",
      "  0.35761176  0.35761176  0.37969977  0.37340958  0.35761176  0.35761176\n",
      "  0.38239401  0.38239401  0.35761176  0.35761176  0.38051511  0.38051511\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742\n",
      "  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742\n",
      "  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742\n",
      "  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742  0.47677742\n",
      "  0.23952333  0.23952333  0.28317365  0.29444887  0.23952333  0.23952333\n",
      "  0.28705582  0.28705582  0.23952333  0.23952333  0.29234946  0.29234946\n",
      "  0.23952333  0.23952333  0.29157776  0.28416098  0.23952333  0.23952333\n",
      "  0.28705582  0.28705582  0.23952333  0.23952333  0.29234946  0.29234946\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.47818842  0.47818842  0.47872154  0.4784152   0.47818842  0.47818842\n",
      "  0.4787548   0.4787548   0.47818842  0.47818842  0.47847704  0.47847704\n",
      "  0.47818842  0.47818842  0.47851142  0.47848462  0.47818842  0.47818842\n",
      "  0.4787548   0.4787548   0.47818842  0.47818842  0.47847704  0.47847704\n",
      "  0.35761176  0.35761176  0.39530289  0.38060495  0.35761176  0.35761176\n",
      "  0.38239401  0.38239401  0.35761176  0.35761176  0.38051511  0.38051511\n",
      "  0.35761176  0.35761176  0.36505653  0.36112787  0.35761176  0.35761176\n",
      "  0.38239401  0.38239401  0.35761176  0.35761176  0.38051511  0.38051511\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.22788339  0.22788339  0.22805633  0.2280962   0.22788339  0.22788339\n",
      "  0.22794126  0.22794126  0.22788339  0.22788339  0.22797474  0.22797474\n",
      "  0.22788339  0.22788339  0.22812121  0.22799343  0.22788339  0.22788339\n",
      "  0.22794126  0.22794126  0.22788339  0.22788339  0.22797474  0.22797474\n",
      "  0.32515425  0.32515425  0.32299842  0.32311171  0.32515425  0.32515425\n",
      "  0.32302034  0.32302034  0.32515425  0.32515425  0.32333362  0.32333362\n",
      "  0.32515425  0.32515425  0.32317848  0.32301642  0.32515425  0.32515425\n",
      "  0.32302034  0.32302034  0.32515425  0.32515425  0.32333362  0.32333362\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.05887438 -0.05887438 -0.0584826  -0.0582584  -0.05887438 -0.05887438\n",
      " -0.05804426 -0.05804426 -0.05887438 -0.05887438 -0.05814919 -0.05814919\n",
      " -0.05887438 -0.05887438 -0.05851435 -0.0583184  -0.05887438 -0.05887438\n",
      " -0.05804426 -0.05804426 -0.05887438 -0.05887438 -0.05814919 -0.05814919\n",
      "  0.1180886   0.1180886   0.16711296  0.16423464  0.1180886   0.1180886\n",
      "  0.16501406  0.16501406  0.1180886   0.1180886   0.16775079  0.16775079\n",
      "  0.1180886   0.1180886   0.16660726  0.16426883  0.1180886   0.1180886\n",
      "  0.16501406  0.16501406  0.1180886   0.1180886   0.16775079  0.16775079\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.22788339  0.22788339  0.22801026  0.22807072  0.22788339  0.22788339\n",
      "  0.22794126  0.22794126  0.22788339  0.22788339  0.22797474  0.22797474\n",
      "  0.22788339  0.22788339  0.22791241  0.22800765  0.22788339  0.22788339\n",
      "  0.22794126  0.22794126  0.22788339  0.22788339  0.22797474  0.22797474\n",
      "  0.32515425  0.32515425  0.32308167  0.32321694  0.32515425  0.32515425\n",
      "  0.32302034  0.32302034  0.32515425  0.32515425  0.32333362  0.32333362\n",
      "  0.32515425  0.32515425  0.32312689  0.32303041  0.32515425  0.32515425\n",
      "  0.32302034  0.32302034  0.32515425  0.32515425  0.32333362  0.32333362\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.05887438 -0.05887438 -0.05846373 -0.05823309 -0.05887438 -0.05887438\n",
      " -0.05804426 -0.05804426 -0.05887438 -0.05887438 -0.05814919 -0.05814919\n",
      " -0.05887438 -0.05887438 -0.05812521 -0.05811047 -0.05887438 -0.05887438\n",
      " -0.05804426 -0.05804426 -0.05887438 -0.05887438 -0.05814919 -0.05814919\n",
      "  0.1180886   0.1180886   0.16682641  0.167453    0.1180886   0.1180886\n",
      "  0.16501406  0.16501406  0.1180886   0.1180886   0.16775079  0.16775079\n",
      "  0.1180886   0.1180886   0.16459287  0.16942091  0.1180886   0.1180886\n",
      "  0.16501406  0.16501406  0.1180886   0.1180886   0.16775079  0.16775079]\n",
      "  warnings.warn(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:909: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/usuario/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 549.8033085805364, tolerance: 4.27807523\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 1.0], &#x27;copy_X&#x27;: [True, False],\n",
       "                         &#x27;fit_intercept&#x27;: [True, False],\n",
       "                         &#x27;max_iter&#x27;: [None, 1000], &#x27;positive&#x27;: [True, False],\n",
       "                         &#x27;precompute&#x27;: [True, False],\n",
       "                         &#x27;random_state&#x27;: [None, 3, 5],\n",
       "                         &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                         &#x27;warm_start&#x27;: [True, False]},\n",
       "             verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 1.0], &#x27;copy_X&#x27;: [True, False],\n",
       "                         &#x27;fit_intercept&#x27;: [True, False],\n",
       "                         &#x27;max_iter&#x27;: [None, 1000], &#x27;positive&#x27;: [True, False],\n",
       "                         &#x27;precompute&#x27;: [True, False],\n",
       "                         &#x27;random_state&#x27;: [None, 3, 5],\n",
       "                         &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                         &#x27;warm_start&#x27;: [True, False]},\n",
       "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0, 1.0], 'copy_X': [True, False],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'max_iter': [None, 1000], 'positive': [True, False],\n",
       "                         'precompute': [True, False],\n",
       "                         'random_state': [None, 3, 5],\n",
       "                         'selection': ['cyclic', 'random'],\n",
       "                         'warm_start': [True, False]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "grid_hp_lasso_reg = {\n",
    "    'alpha': [0, 1.0],\n",
    "    'fit_intercept': [True, False],\n",
    "    'precompute': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'max_iter': [None, 1000],\n",
    "    'warm_start': [True, False],\n",
    "    'positive': [True, False],\n",
    "    'random_state': [None, 3, 5],\n",
    "    'selection': ['cyclic', 'random']\n",
    "}\n",
    "\n",
    "lasso_reg_model_valence = GridSearchCV(\n",
    "    estimator = Lasso(), \n",
    "    param_grid = grid_hp_lasso_reg, \n",
    "    cv = 2,\n",
    "    n_jobs = -1,\n",
    "    verbose = 10,\n",
    ")\n",
    "\n",
    "lasso_reg_model_valence.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ec6b4cd-281e-4d1d-804e-eb5015353ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': False,\n",
       " 'max_iter': 1000,\n",
       " 'positive': True,\n",
       " 'precompute': True,\n",
       " 'random_state': 3,\n",
       " 'selection': 'random',\n",
       " 'warm_start': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg_model_valence.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbfe8917-bf3b-4065-999d-5bd0f2cc7a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5027616162126423"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg_model_valence.score(X_test_val, y_test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec1acf-7d47-4eb7-81d7-fa6beeba40c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f3b611-0411-4149-85ce-65396dbc5312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece0f541-2418-4b5c-913b-0a82b4c0e5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x749e0a8013a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decission Tree Regressor</th>\n",
       "      <td>0.841848</td>\n",
       "      <td>1.163597</td>\n",
       "      <td>0.104391</td>\n",
       "      <td>0.033407</td>\n",
       "      <td>0.176916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.691462</td>\n",
       "      <td>0.720338</td>\n",
       "      <td>0.445563</td>\n",
       "      <td>0.021412</td>\n",
       "      <td>0.146273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.983962</td>\n",
       "      <td>1.568538</td>\n",
       "      <td>-0.207288</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.217489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MAE       MSE        R2     RMSLE      MAPE\n",
       "Decission Tree Regressor  0.841848  1.163597  0.104391  0.033407  0.176916\n",
       "Linear Regression         0.691462  0.720338  0.445563  0.021412  0.146273\n",
       "KNN                       0.983962  1.568538 -0.207288  0.048029  0.217489"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## VALENCE ##########\n",
    "\n",
    "# ----- seleccion de variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(explicative, objective_valence, test_size=0.03, random_state=42)\n",
    "\n",
    "# ------ inicializacion matriz de comparación\n",
    "compare_valence = pd.DataFrame(y_test_val)\n",
    "\n",
    "# --- árbol de decisión\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_regr_model_valence = DecisionTreeRegressor(max_depth = 7)\n",
    "tree_regr_model_valence.fit(X=X_train_val, y=y_train_val)\n",
    "pred_tree_regr_model_valence = tree_regr_model_valence.predict(X_test_val)\n",
    "compare_valence = pd.concat([compare_valence.reset_index(), pd.DataFrame(pred_tree_regr_model_valence, columns=['tree_reg'])],\n",
    "                            axis = 1,\n",
    "                            ignore_index=False)\n",
    "\n",
    "\n",
    "# ------ regresion linear\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg_linnear_model_valence = LinearRegression().fit(X=X_train_val, y=y_train_val)\n",
    "pred_linear_model_valence = reg_linnear_model_valence.predict(X_test_val)\n",
    "compare_valence = pd.concat([compare_valence, pd.DataFrame(pred_linear_model_valence, columns=['linear_reg'])],\n",
    "                            axis = 1,\n",
    "                            ignore_index=False)\n",
    "\n",
    "# ------ regresion knn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_model_valence = KNeighborsRegressor(n_neighbors=2)\n",
    "knn_model_valence.fit(X=X_train_val, y=y_train_val)\n",
    "pred_knn_model_valence = knn_model_valence.predict(X_test_val)\n",
    "compare_valence = pd.concat([compare_valence, pd.DataFrame(pred_knn_model_valence, columns=['knn'])],\n",
    "                            axis = 1,\n",
    "                            ignore_index=False)\n",
    "\n",
    "\n",
    "#print(compare_valence)\n",
    "compare_valence.drop(columns=['index']).plot(figsize=(20,4));\n",
    "\n",
    "#### ------ métricas\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# valor cuadrático medio (MAE)\n",
    "mae_tree_reg_valence = mean_absolute_error(compare_valence['valence'], compare_valence['tree_reg'])\n",
    "mae_linear_reg_valence = mean_absolute_error(compare_valence['valence'], compare_valence['linear_reg'])\n",
    "mae_knn_valence = mean_absolute_error(compare_valence['valence'], compare_valence['knn'])\n",
    "\n",
    "# valor cuadrático medio (MSE)\n",
    "mse_tree_reg_valence = mean_squared_error(compare_valence['valence'], compare_valence['tree_reg'])\n",
    "mse_linear_reg_valence = mean_squared_error(compare_valence['valence'], compare_valence['linear_reg'])\n",
    "mse_knn_valence = mean_squared_error(compare_valence['valence'], compare_valence['knn'])\n",
    "\n",
    "# r2\n",
    "r2_tree_reg_valence = r2_score(compare_valence['valence'], compare_valence['tree_reg'])\n",
    "r2_linear_reg_valence = r2_score(compare_valence['valence'], compare_valence['linear_reg'])\n",
    "r2_knn_valence = r2_score(compare_valence['valence'], compare_valence['knn'])\n",
    "\n",
    "# mean squared log error (RMSLE)\n",
    "rmsle_tree_reg_valence = mean_squared_log_error(compare_valence['valence'], compare_valence['tree_reg'])\n",
    "rmsle_linear_reg_valence = mean_squared_log_error(compare_valence['valence'], compare_valence['linear_reg'])\n",
    "rmsle_knn_valence = mean_squared_log_error(compare_valence['valence'], compare_valence['knn'])\n",
    "\n",
    "# mean absolute percentage error (MAPE)\n",
    "mape_tree_reg_valence = mean_absolute_percentage_error(compare_valence['valence'], compare_valence['tree_reg'])\n",
    "mape_linear_reg_valence = mean_absolute_percentage_error(compare_valence['valence'], compare_valence['linear_reg'])\n",
    "mape_knn_valence = mean_absolute_percentage_error(compare_valence['valence'], compare_valence['knn'])\n",
    "\n",
    "\n",
    "metrics_valence = pd.DataFrame([[mae_tree_reg_valence, mse_tree_reg_valence, r2_tree_reg_valence, rmsle_tree_reg_valence, mape_tree_reg_valence],\n",
    "                                [mae_linear_reg_valence, mse_linear_reg_valence, r2_linear_reg_valence, rmsle_linear_reg_valence, mape_linear_reg_valence],\n",
    "                                [mae_knn_valence, mse_knn_valence, r2_knn_valence, rmsle_knn_valence, mape_knn_valence]], \n",
    "                               columns=['MAE', 'MSE', 'R2', 'RMSLE', 'MAPE'], \n",
    "                               index=['Decission Tree Regressor', 'Linear Regression', 'KNN'])\n",
    "metrics_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9408af76-db95-472e-8ee1-47bc780f177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7c851911fd80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/usuario/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decission Tree Regressor</th>\n",
       "      <td>0.835467</td>\n",
       "      <td>1.235305</td>\n",
       "      <td>0.240068</td>\n",
       "      <td>0.036295</td>\n",
       "      <td>0.181288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.866971</td>\n",
       "      <td>1.136737</td>\n",
       "      <td>0.300704</td>\n",
       "      <td>0.033404</td>\n",
       "      <td>0.184889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.884604</td>\n",
       "      <td>1.197884</td>\n",
       "      <td>0.263088</td>\n",
       "      <td>0.036601</td>\n",
       "      <td>0.192343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MAE       MSE        R2     RMSLE      MAPE\n",
       "Decission Tree Regressor  0.835467  1.235305  0.240068  0.036295  0.181288\n",
       "Linear Regression         0.866971  1.136737  0.300704  0.033404  0.184889\n",
       "KNN                       0.884604  1.197884  0.263088  0.036601  0.192343"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## AROUSAL ##########\n",
    "\n",
    "# ----- seleccion de variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_ar, X_test_ar, y_train_ar, y_test_ar = train_test_split(explicative, objective_arousal, test_size=0.03, random_state=42)\n",
    "\n",
    "# ------ inicializacion matriz de comparación\n",
    "compare_arousal = pd.DataFrame(y_test_ar)\n",
    "\n",
    "# --- árbol de decisión\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_regr_model_arousal = DecisionTreeRegressor(max_depth = 7)\n",
    "tree_regr_model_arousal.fit(X=X_train_ar, y=y_train_ar)\n",
    "pred_tree_regr_model_arousal = tree_regr_model_arousal.predict(X_test_ar)\n",
    "compare_arousal = pd.concat([compare_arousal.reset_index(), pd.DataFrame(pred_tree_regr_model_arousal, columns=['tree_reg'])],\n",
    "                            axis = 1,\n",
    "                            ignore_index=False)\n",
    "\n",
    "\n",
    "# ------ regresion linear\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg_linnear_model_arousal = LinearRegression().fit(X=X_train_ar, y=y_train_ar)\n",
    "pred_linear_model_arousal = reg_linnear_model_arousal.predict(X_test_ar)\n",
    "compare_arousal = pd.concat([compare_arousal, pd.DataFrame(pred_linear_model_arousal, columns=['linear_reg'])],\n",
    "                            axis = 1,\n",
    "                            ignore_index=False)\n",
    "\n",
    "# ------ regresion knn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_model_arousal = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model_arousal.fit(X=X_train_ar, y=y_train_ar)\n",
    "pred_knn_model_arousal = knn_model_arousal.predict(X_test_ar)\n",
    "compare_arousal = pd.concat([compare_arousal, pd.DataFrame(pred_knn_model_arousal, columns=['knn'])],\n",
    "                            axis = 1,\n",
    "                            ignore_index=False)\n",
    "\n",
    "compare_arousal\n",
    "\n",
    "compare_arousal.drop(columns=['index']).plot(figsize=(20,4));\n",
    "\n",
    "#### ------ métricas\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# valor cuadrático medio (MAE)\n",
    "mae_tree_reg_arousal = mean_absolute_error(compare_arousal['arousal'], compare_arousal['tree_reg'])\n",
    "mae_linear_reg_arousal = mean_absolute_error(compare_arousal['arousal'], compare_arousal['linear_reg'])\n",
    "mae_knn_arousal = mean_absolute_error(compare_arousal['arousal'], compare_arousal['knn'])\n",
    "\n",
    "# valor cuadrático medio (MSE)\n",
    "mse_tree_reg_arousal = mean_squared_error(compare_arousal['arousal'], compare_arousal['tree_reg'])\n",
    "mse_linear_reg_arousal = mean_squared_error(compare_arousal['arousal'], compare_arousal['linear_reg'])\n",
    "mse_knn_arousal = mean_squared_error(compare_arousal['arousal'], compare_arousal['knn'])\n",
    "\n",
    "# r2\n",
    "r2_tree_reg_arousal = r2_score(compare_arousal['arousal'], compare_arousal['tree_reg'])\n",
    "r2_linear_reg_arousal = r2_score(compare_arousal['arousal'], compare_arousal['linear_reg'])\n",
    "r2_knn_arousal = r2_score(compare_arousal['arousal'], compare_arousal['knn'])\n",
    "\n",
    "# mean squared log error (RMSLE)\n",
    "rmsle_tree_reg_arousal = mean_squared_log_error(compare_arousal['arousal'], compare_arousal['tree_reg'])\n",
    "rmsle_linear_reg_arousal = mean_squared_log_error(compare_arousal['arousal'], compare_arousal['linear_reg'])\n",
    "rmsle_knn_arousal = mean_squared_log_error(compare_arousal['arousal'], compare_arousal['knn'])\n",
    "\n",
    "# mean absolute percentage error (MAPE)\n",
    "mape_tree_reg_arousal = mean_absolute_percentage_error(compare_arousal['arousal'], compare_arousal['tree_reg'])\n",
    "mape_linear_reg_arousal = mean_absolute_percentage_error(compare_arousal['arousal'], compare_arousal['linear_reg'])\n",
    "mape_knn_arousal = mean_absolute_percentage_error(compare_arousal['arousal'], compare_arousal['knn'])\n",
    "\n",
    "\n",
    "metrics_arousal = pd.DataFrame([[mae_tree_reg_arousal, mse_tree_reg_arousal, r2_tree_reg_arousal, rmsle_tree_reg_arousal, mape_tree_reg_arousal],\n",
    "                                [mae_linear_reg_arousal, mse_linear_reg_arousal, r2_linear_reg_arousal, rmsle_linear_reg_arousal, mape_linear_reg_arousal],\n",
    "                                [mae_knn_arousal, mse_knn_arousal, r2_knn_arousal, rmsle_knn_arousal, mape_knn_arousal]], \n",
    "                               columns=['MAE', 'MSE', 'R2', 'RMSLE', 'MAPE'], \n",
    "                               index=['Decission Tree Regressor', 'Linear Regression', 'KNN'])\n",
    "metrics_arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e68bc5c4-0896-44bb-93f1-89a35994aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24006762, 0.30070426, 0.26308786])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_arousal[\"R2\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f6a34-7824-4012-8901-8f94b8aad4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0069ed-6a46-4b15-b651-463f4ddf6221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3a37d-5dcf-404c-966e-4c27bc01fb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11297e-54b6-4746-a42e-6b11eab04c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d02ae4-4d66-40df-8b01-8d9cb7f50363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e603f9a2-9993-4c7a-b995-410ac1f157ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975860d1-32e4-44a6-83cb-7d09a19b535a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c9b5a9-3c7c-48dd-8b84-f2786751c6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf98e5-0986-41a0-a7a1-37ec406aa65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6f43a-0ad6-45da-b337-507f9427aecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983adc6d-fc75-4883-925f-b14c3e57f500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554f175-e345-44ab-860c-f7cd056d4ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78dadb-ca1b-40d7-8976-532839f41d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9644467-f977-414d-881e-3979e01768a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf5594f-69e4-4ab1-aeae-f68bf24e5a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f420e663-dbf5-4e2e-aa67-d742e7aa93ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558f068-4455-4c70-847d-2643ddb0456d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ab6de-3c6b-4b70-9ca0-569a29bba193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a636c1-8a7c-45ff-90b2-306e61da5386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb6d9d-27a7-4563-a6fe-8c6a62a35d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a8556-2764-4879-973b-c8ebf787df73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a9238-12b0-4510-96fa-e1bbc37fcfd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf305e4-5656-408f-ba89-b1d8cd4c7313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66efc781-28cb-4f50-a731-7ce65e8b3628",
   "metadata": {},
   "source": [
    "////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "RELACIÓN EMOCIÓN CON ESTILO MUSICAL\n",
    "////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed09a04-3ce2-426b-9904-73692cc8f615",
   "metadata": {},
   "source": [
    "Recopilación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f0f597f-ac54-4780-9ba9-f83585c65068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>valence_mean</th>\n",
       "      <th>arousal_mean</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>\\tBlues\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>\\tBlues\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>\\tBlues\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>\\tBlues\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>\\tBlues\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>928</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>\\tRock\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>931</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>\\tRock\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>932</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>\\tRock\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>934</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>\\tRock\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>936</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>\\tRock\\t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     song_id   valence_mean   arousal_mean      Genre\n",
       "0          2            3.1            3.0  \\tBlues\\t\n",
       "1          3            3.5            3.3  \\tBlues\\t\n",
       "2          4            5.7            5.5  \\tBlues\\t\n",
       "3          5            4.4            5.3  \\tBlues\\t\n",
       "4          7            5.8            6.4  \\tBlues\\t\n",
       "..       ...            ...            ...        ...\n",
       "695      928            5.0            4.0   \\tRock\\t\n",
       "696      931            6.3            6.5   \\tRock\\t\n",
       "697      932            4.5            4.9   \\tRock\\t\n",
       "698      934            6.2            6.4   \\tRock\\t\n",
       "699      936            5.4            4.7   \\tRock\\t\n",
       "\n",
       "[700 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract valence and arousal values from files\n",
    "emotion_matrix = pd.read_csv(VALENCE_FILE)\n",
    "emotion = emotion_matrix[['song_id', ' valence_mean', ' arousal_mean']]\n",
    "#emotion\n",
    "genre_matrix = pd.read_csv(GENRE_FILE)\n",
    "genre = genre_matrix['Genre']\n",
    "genre_emotion_matrix = pd.concat([emotion, genre], axis = 1)\n",
    "genre_emotion = genre_emotion_matrix.head(700)\n",
    "genre_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ec0844-c54a-438c-b34d-bde470004eb7",
   "metadata": {},
   "source": [
    "ARBOL DE DECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a228084a-313e-46a0-b6ff-41cf3f4c3914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables\n",
    "exp = genre_emotion[[' valence_mean', ' arousal_mean']]\n",
    "obj = genre_emotion.drop(columns=['song_id', ' valence_mean', ' arousal_mean'])\n",
    "\n",
    "X_train_gen, X_test_gen, y_train_gen, y_test_gen = train_test_split(exp, obj, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c11a2-710b-4394-8b37-342809d8d273",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e11b4506-ebdc-4820-81e4-84aff9b54568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_genre = DecisionTreeClassifier(max_depth = 3)\n",
    "model_genre.fit(X=X_train_gen, y=y_train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c7352a2-8ed7-42e9-bc5d-ebe0ec79cc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(14, 4))\n",
    "plot_tree(decision_tree=model_genre, feature_names=exp.columns, filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a755553-22ac-45a1-a35a-6ed6ceba73be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Genre</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>\\tClassical\\t</td>\n",
       "      <td>\\tClassical\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>\\tJazz\\t</td>\n",
       "      <td>\\tJazz\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>396</td>\n",
       "      <td>\\tElectronic\\t</td>\n",
       "      <td>\\tClassical\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155</td>\n",
       "      <td>\\tClassical\\t</td>\n",
       "      <td>\\tClassical\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>\\tElectronic\\t</td>\n",
       "      <td>\\tElectronic\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>549</td>\n",
       "      <td>\\tJazz\\t</td>\n",
       "      <td>\\tElectronic\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>211</td>\n",
       "      <td>\\tClassical\\t</td>\n",
       "      <td>\\tPop\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>55</td>\n",
       "      <td>\\tBlues\\t</td>\n",
       "      <td>\\tClassical\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>135</td>\n",
       "      <td>\\tClassical\\t</td>\n",
       "      <td>\\tClassical\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>672</td>\n",
       "      <td>\\tRock\\t</td>\n",
       "      <td>\\tElectronic\\t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index           Genre            pred\n",
       "0     158   \\tClassical\\t   \\tClassical\\t\n",
       "1     500        \\tJazz\\t        \\tJazz\\t\n",
       "2     396  \\tElectronic\\t   \\tClassical\\t\n",
       "3     155   \\tClassical\\t   \\tClassical\\t\n",
       "4     321  \\tElectronic\\t  \\tElectronic\\t\n",
       "..    ...             ...             ...\n",
       "65    549        \\tJazz\\t  \\tElectronic\\t\n",
       "66    211   \\tClassical\\t         \\tPop\\t\n",
       "67     55       \\tBlues\\t   \\tClassical\\t\n",
       "68    135   \\tClassical\\t   \\tClassical\\t\n",
       "69    672        \\tRock\\t  \\tElectronic\\t\n",
       "\n",
       "[70 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_genre = model_genre.predict(X_test_gen)\n",
    "df_pred_genre = pd.DataFrame(pred_genre, columns=['pred'])\n",
    "y_test_genre_df = pd.DataFrame(y_test_gen)\n",
    "dif_genre = pd.concat([y_test_genre_df.reset_index(), df_pred_genre], axis = 1)\n",
    "dif_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a44ea87f-4eba-4ac9-8c4d-740263d50053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7b58e5568210>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matriz de confusion\n",
    "import sklearn.metrics\n",
    "conf_matrix = sklearn.metrics.confusion_matrix(dif_genre['Genre'], dif_genre['pred'])\n",
    "conf_matrix_displayed = sklearn.metrics.ConfusionMatrixDisplay(conf_matrix)\n",
    "conf_matrix_displayed.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9346e126-7861-479c-9d30-4cedec0c52bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(dif_genre['Genre'], dif_genre['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913991a-0ebe-435f-8aac-f4d89a51ff5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975203ff-b822-4663-a6ad-d8e77558f54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
